{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To NIR: Tracing PyTorch\n",
    "\n",
    "When creating NIR nodes from PyTorch, we go through the PyTorch modules to create a graph structure that we can populate with NIR nodes.\n",
    "This \"going through\" is what we refer to as \"tracing\" because we have to track the path of signals through potentially complex modules structure, so we know where to put input signals and read output signals.\n",
    "\n",
    "The tracing happens in two steps\n",
    "1. First, we find all the PyTorch Modules that should be mapped to NIR nodes\n",
    "2. Second, we trace through the PyTorch modules to find the edges for the NIR graph.\n",
    "\n",
    "We use the [symbolic tracing from `torch.fx`](https://pytorch.org/docs/stable/fx.html) to go through the graphs, because it's fast and it allows us to reconstruct NIR Graphs without executing any code.\n",
    "\n",
    "## Mapping nodes\n",
    "For the first step, we need to know which nodes can be mapped (the keys) and how they should be mapped (a function that maps `torch.nn.Module`s to `nir.NIRNode`s).\n",
    "To that end, `nirtorch` expects a dictionary of type `Dictionary[torch.nn.Module, Callable[[torch.nn.Module], nir.NIRNode]]`.\n",
    "That is, a dictionary with `torch.nn.Module`s as keys and functions that map `torch.nn.Module -> nir.NIRNode`.\n",
    "One may wonder why we don't just use a single function to convert `torch.nn.Module` to `nir.NIRNode`s instead of a dictionary, but the keys in the dictionary are vital in understanding which modules to map.\n",
    "\n",
    "We call the keys in the `module_map` **leaf nodes** because they are not processed further: if they are included in the `module_map` dictionary, the corresponding mapping function (`Callable[[torch.nn.Module], nir.NIRNode]`) needs to deal with any potential submodules.\n",
    "Conversely, if a module is not in the dictionary (such as a `torch.nn.ModuleList`), we have to traverse the modules inside that module.\n",
    "\n",
    "## Tracing edges\n",
    "Since edges in NIR does not have any logic, finding the edges in the graph is purely a matter of creating the input-output relations.\n",
    "Tracing edges is done by going through the calls in the `torch.nn.Module`s and finding the source node (input signal) for the call and map that to the node that represents the module call.\n",
    "Provided that all modules are well defined, this step is relatively straigth-forward, although there are some complications regarding pure function calls (as opposed to module calls), we cover below in [Mapping function calls](#mapping-function-calls).\n",
    "\n",
    "## Tracing in practice\n",
    "\n",
    "In practice, the behavior above is implemented in `nirtorch.torch_to_nir` with the following signature:\n",
    "\n",
    "```python\n",
    "def torch_to_nir(\n",
    "    module: torch.nn.Module,\n",
    "    module_map: Dict[torch.nn.Module, Callable[[torch.nn.Module], nir.NIRNode]],\n",
    "    default_dict: Optional[\n",
    "        Dict[torch.nn.Module, Callable[[torch.nn.Module], nir.NIRNode]]\n",
    "    ] = None,\n",
    ") -> nir.NIRGraph: ...\n",
    "```\n",
    "\n",
    "Here is a [short, self-contained example](https://www.sscce.org/) on how you to map a `torch.nn.AvgPool2d` to `nir.AvgPool2d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool2d(kernel_size=array([2, 2]), stride=array(0), padding=array(1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nir, nirtorch, numpy as np, torch\n",
    "\n",
    "# First, we describe the PyTorch module we want to convert\n",
    "torch_module = torch.nn.AvgPool2d(kernel_size=(2, 2), stride=0, padding=1)\n",
    "\n",
    "# Second, we define the dictionary\n",
    "torch_to_nir_map = {\n",
    "    torch.nn.AvgPool2d: lambda module: nir.AvgPool2d(\n",
    "        kernel_size=np.array(module.kernel_size),\n",
    "        stride=np.array(module.stride),\n",
    "        padding=np.array(module.padding)\n",
    "    )\n",
    "}\n",
    "\n",
    "# Finally, we call nirtorch with the node and dictionary\n",
    "converted_module = nirtorch.torch_to_nir(torch_module, torch_to_nir_map)\n",
    "converted_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we convert the module parameters to Numpy arrays.\n",
    "You can use in principle the raw numbers, but we recommend using numpy arrays for consistency.\n",
    "\n",
    "Note also that the mapping functions can output arbitrary NIR nodes, so you can output arbitrary nodes if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping function calls\n",
    "\n",
    "The above method works well for modules, but what about modules with function calls like addition `+`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_add(x: torch.Tensor, y: torch.Tensor):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the difference between NIR and PyTorch becomes apparent: NIR is not a procedural graph, like PyTorch, where we execute one thing after the other and eventually return the output.\n",
    "Think about NIR as a physical switchboard where we plug wires into different sockets to form connections between nodes.\n",
    "This only works for a subset of functions.\n",
    "\n",
    "Addition works well because we can rewire this PyTorch graph\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    plus[my_add]\n",
    "    x --> plus\n",
    "    y --> plus\n",
    "    plus --> next_module\n",
    "```\n",
    "\n",
    "Into\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    x --> next_module\n",
    "    y --> next_module\n",
    "```\n",
    "\n",
    "by removing the `+` node and wire both `x` and `y` directly to the output.\n",
    "This works, because \"addition\" in NIR corresponds to summing two signals.\n",
    "\n",
    "Here's an example of a module that returns the sum two linearities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NIRGraph(nodes={'x': Input(input_type={'input': array([1])}), 'lin': Affine(weight=array([[-0.29883528]], dtype=float32), bias=array([-0.36035502], dtype=float32), input_type={'input': array([1])}, output_type={'output': array([1])}, metadata={}), 'lin_1': Affine(weight=array([[-0.29883528]], dtype=float32), bias=array([-0.36035502], dtype=float32), input_type={'input': array([1])}, output_type={'output': array([1])}, metadata={}), 'output': Output(output_type={'output': array([1])})}, edges=[('x', 'lin'), ('x', 'lin_1'), ('lin', 'output'), ('lin_1', 'output')], input_type={'x': {'input': array([1])}}, output_type={'output': {'output': array([1])}}, metadata={})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nir, nirtorch, numpy as np, torch\n",
    "\n",
    "# First, we describe the PyTorch module we want to convert, this time with addition\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x) + self.lin(x)\n",
    "\n",
    "torch_module = MyModule()\n",
    "\n",
    "# Second, we define the dictionary\n",
    "torch_to_nir_map = {\n",
    "    torch.nn.Linear: lambda module: nir.Affine(\n",
    "        weight=module.weight.detach().numpy(),\n",
    "        bias=module.bias.detach().numpy()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Finally, we call nirtorch with the node and dictionary\n",
    "converted_module = nirtorch.torch_to_nir(torch_module, torch_to_nir_map)\n",
    "converted_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the following graph:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    x --> lin\n",
    "    x --> lin_1\n",
    "    lin --> output\n",
    "    lin_1 --> output\n",
    "```\n",
    "\n",
    "Notice the two nodes (`lin` and `lin_1`) with two additional edges `(lin, output)` and `(lin_1, output)`.\n",
    "This is \"addition\" in NIR, because the signals will sum upon arrival.\n",
    "\n",
    "Other functions are, presently, not supported.\n",
    "[Get in touch](https://neuroir.org/) or [open an issue](https://github.com/neuromorphs/NIRTorch/issues/) if you think this should change!\n",
    "We are more than happy to hear your input and adapt to your needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
