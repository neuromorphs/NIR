{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To PyTorch: Interpreting NIR\n",
    "\n",
    "We rely on [`torch.fx`](https://pytorch.org/docs/stable/fx.html) to interpret NIR graphs.\n",
    "We first translate all the NIR nodes into PyTorch nodes, by going through the nodes in the NIR graph one by one.\n",
    "This mechanism relies on a dictionary given by the user that tells `nirtorch` (1) which modules can be mapped and (2) how to map them.\n",
    "That is, we need a dictionary of type `Dict[nir.NIRNode, Callable[[nir.NIRNode], torch.nn.Module]]`.\n",
    "One may wonder why we don't just use a function from `nir.NIRNode -> torch.nn.Module` and the answer is that having a set of nodes that *do* exist helps `nirtorch` simplify the parsing.\n",
    "It is entirely possible to only provide partial mappings, which `nirtorch` will handle by skipping those nodes - except in cases where the mapping is required.\n",
    "\n",
    "## Intepreting in detail\n",
    "The interpreting happens in two steps.\n",
    "1. First, we map all the nodes individually, using the dictionary defined above.\n",
    "2. Second, we trace the graph and plug the translated nodes into a [Torch FX graph](https://pytorch.org/docs/stable/fx.html#torch.fx.Graph).\n",
    "The second step gives us a fully-executable [torch.fx.GraphModule](https://pytorch.org/docs/stable/fx.html#torch.fx.GraphModule) that we can execute.\n",
    "Note that the execution is stateful, as described in [State management in NIRTorch](#state).\n",
    "\n",
    "All this is implemented in the function `nirtorch.nir_to_torch` which has the following signature:\n",
    "\n",
    "```python\n",
    "def nir_to_torch(\n",
    "    nir_node: nir.NIRGraph,\n",
    "    node_map: NodeMapType,\n",
    "    default_map: NodeMapType = DEFAULT_MAP,\n",
    ") -> torch.fx.GraphModule:\n",
    "```\n",
    "\n",
    "The `nir_node` parameter is the NIR node we wish to convert.\n",
    "It can be a singular node or a `nir.NIRGraph`, which can contain multiple nodes (and subgraphs).\n",
    "The `node_map` parameter is the dictionary above, with type signature `Dict[nir.NIRNode, Callable[[nir.NIRNode], torch.nn.Module]]`, that we use to look up supported nodes and convert nodes in the first step mentioned above.\n",
    "\n",
    "Here is a [short, self-contained example](https://www.sscce.org/) on how you can map a `nir.AvgPool2d` to `torch.nn.AvgPool2d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (avgpool2d): AvgPool2d(kernel_size=(tensor(2), tensor(2)), stride=tensor([1]), padding=(tensor(0), tensor(0)))\n",
       "  (linear): Linear(in_features=5, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nir, nirtorch, numpy as np, torch\n",
    "\n",
    "# First, we describe the NIR graph we need as input\n",
    "nir_avgpool = nir.AvgPool2d(kernel_size=np.array([2, 2]), stride=np.array([1]), padding=np.array([0, 0]))\n",
    "nir_linear = nir.Linear(weight=np.ones((5, 5), dtype=np.float32))\n",
    "nir_graph = nir.NIRGraph.from_list(nir_avgpool, nir_linear) # Constructs a graph with a single node: AvgPool2d\n",
    "\n",
    "# Second, we define the mapping\n",
    "nir_to_torch_map = {\n",
    "    nir.AvgPool2d: lambda node: torch.nn.AvgPool2d(\n",
    "        kernel_size=tuple(torch.from_numpy(node.kernel_size)),\n",
    "        stride=torch.from_numpy(node.stride),\n",
    "        padding=tuple(torch.from_numpy(node.padding))\n",
    "    )\n",
    "}\n",
    "\n",
    "# Finally, we call nirtorch with the node and dictionary\n",
    "converted_module = nirtorch.nir_to_torch(nir_graph, nir_to_torch_map)\n",
    "converted_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `torch.from_numpy` call, which ensures that the Numpy arrays coming from NIR is correctly cast to PyTorch tensors.\n",
    "You may also have observed that we cast some of the parameters to `torch.nn.AvgPool2d` to tuples to adhere to the 2-dimensional average pooling arguments.\n",
    "\n",
    "Note also that we did not specify a mapping for the `nir.Linear` module. That's because `nirtorch` provides default mappings for the simples modules (like `nir.Linear`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5., 5., 5., 5., 5.],\n",
       "          [5., 5., 5., 5., 5.],\n",
       "          [5., 5., 5., 5., 5.],\n",
       "          [5., 5., 5., 5., 5.],\n",
       "          [5., 5., 5., 5., 5.]]], grad_fn=<UnsafeViewBackward0>),\n",
       " {'input': None, 'avgpool2d': None, 'linear': None, 'output': None})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can execute it with a 3-dimensional tensor arranged according to (batch, width, height)\n",
    "converted_module(torch.ones(1, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output is a tuple, where the second tuple is the state (which is empty, because average pooling is stateless)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting default dictionaries\n",
    "\n",
    "There is a third parameter, `default_map`, which serves to provide defaults to the mapping.\n",
    "`nirtorch` will, by default, map simple models, like `nir.Input`, `nir.Linear -> torch.nn.Linear` and `nir.Affine -> torch.nn.Affine`, but you can override the behavior if you want to provide a different mapping---or remove it all together.\n",
    "Observe what happens when we override the default dicionary (`DEFAULT_MAP`) with an empty dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown node type <class 'nir.ir.graph.Input'>, mapping does not exist in node_map",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n\u001b[1;32m      9\u001b[0m nir_to_torch_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     nir\u001b[38;5;241m.\u001b[39mAvgPool2d: \u001b[38;5;28;01mlambda\u001b[39;00m node: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mAvgPool2d(\n\u001b[1;32m     11\u001b[0m         kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(node\u001b[38;5;241m.\u001b[39mkernel_size)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Finally, we call nirtorch with the node and dictionary\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m converted_module \u001b[38;5;241m=\u001b[39m \u001b[43mnirtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnir_to_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnir_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnir_to_torch_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m converted_module\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nirtorch/nir_interpreter.py:278\u001b[0m, in \u001b[0;36mnir_to_torch\u001b[0;34m(nir_graph, node_map, default_map)\u001b[0m\n\u001b[1;32m    276\u001b[0m map_with_defaults\u001b[38;5;241m.\u001b[39mupdate(node_map)  \u001b[38;5;66;03m# Overwrite defaults with node_map\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# First convert all nodes into a module dictionary\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m owning_module \u001b[38;5;241m=\u001b[39m \u001b[43m_construct_module_dict_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnir_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_with_defaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Then wire the graph recursively\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _construct_fx_graph(owning_module\u001b[38;5;241m=\u001b[39mowning_module, nir_graph\u001b[38;5;241m=\u001b[39mnir_graph)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nirtorch/nir_interpreter.py:91\u001b[0m, in \u001b[0;36m_construct_module_dict_recursive\u001b[0;34m(nir_graph, node_map)\u001b[0m\n\u001b[1;32m     89\u001b[0m     owning_module[name] \u001b[38;5;241m=\u001b[39m _construct_module_dict_recursive(node, node_map)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     mapped_module \u001b[38;5;241m=\u001b[39m \u001b[43m_map_nir_node_to_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mapped_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m         owning_module[name] \u001b[38;5;241m=\u001b[39m mapped_module\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nirtorch/nir_interpreter.py:77\u001b[0m, in \u001b[0;36m_map_nir_node_to_torch\u001b[0;34m(node, node_map)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_map[\u001b[38;5;28mtype\u001b[39m(node)](node)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown node type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mapping does not exist in node_map\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown node type <class 'nir.ir.graph.Input'>, mapping does not exist in node_map"
     ]
    }
   ],
   "source": [
    "import nir, nirtorch, numpy as np, torch\n",
    "\n",
    "# First, we describe the NIR graph we need as input\n",
    "nir_avgpool = nir.AvgPool2d(kernel_size=np.array([2, 2]), stride=np.array([1]), padding=np.array([0, 0]))\n",
    "nir_linear = nir.Linear(weight=np.ones((5, 5), dtype=np.float32))\n",
    "nir_graph = nir.NIRGraph.from_list(nir_avgpool, nir_linear) # Constructs a graph with a single node: AvgPool2d\n",
    "\n",
    "# Second, we define the mapping\n",
    "nir_to_torch_map = {\n",
    "    nir.AvgPool2d: lambda node: torch.nn.AvgPool2d(\n",
    "        kernel_size=tuple(torch.from_numpy(node.kernel_size)),\n",
    "        stride=torch.from_numpy(node.stride),\n",
    "        padding=tuple(torch.from_numpy(node.padding))\n",
    "    )\n",
    "}\n",
    "\n",
    "# Finally, we call nirtorch with the node and dictionary\n",
    "converted_module = nirtorch.nir_to_torch(nir_graph, nir_to_torch_map, {})\n",
    "converted_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder why the graph has a `nir.Input` node.\n",
    "It's automatically added when constructing a NIR graph via `NIRGraph` (which we do via `nir.NIRGraph.from_list`) to ensure that the graph is well formed and that torch knows where the input and output nodes are.\n",
    "Without the default mapping, `nirtorch` doesn't know how to map the input node or the linear node and will complain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I map tensors to specific devices?\n",
    "\n",
    "`nirtorch` does not care which device your tensors are located, but you may want to cast tensors to specific devices.\n",
    "This can be done with a [partial function application](https://docs.python.org/3/library/functools.html#functools.partial), where you first define your mapping function with an additional `device` parameter, partially apply it when you know the device, and then provide that partially applied function to `nirtorch`. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (avgpool2d): AvgPool2d(kernel_size=(tensor(2), tensor(2)), stride=tensor([1]), padding=(tensor(0), tensor(0)))\n",
       "  (linear): Linear(in_features=5, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nir, nirtorch, numpy as np, torch\n",
    "import functools\n",
    "\n",
    "# First, we describe the NIR graph we need as input\n",
    "nir_avgpool = nir.AvgPool2d(kernel_size=np.array([2, 2]), stride=np.array([1]), padding=np.array([0, 0]))\n",
    "nir_linear = nir.Linear(weight=np.ones((5, 5), dtype=np.float32))\n",
    "nir_graph = nir.NIRGraph.from_list(nir_avgpool, nir_linear) # Constructs a graph with a single node: AvgPool2d\n",
    "\n",
    "# Second, we define the mapping\n",
    "nir_to_torch_map = {\n",
    "    nir.AvgPool2d: lambda node, device: torch.nn.AvgPool2d(    # <--- Note the additional device parameter\n",
    "        kernel_size=tuple(torch.from_numpy(node.kernel_size).to(device)),\n",
    "        stride=torch.from_numpy(node.stride).to(device),\n",
    "        padding=tuple(torch.from_numpy(node.padding).to(device))\n",
    "    )\n",
    "}\n",
    "# We can now partially apply the function at a point in time where we know the device type\n",
    "nir_to_torch_map[nir.AvgPool2d] = functools.partial(\n",
    "    nir_to_torch_map[nir.AvgPool2d], \n",
    "    device=\"cpu\"\n",
    ")\n",
    "# The dictionary now contains a partially applied function that only requires one input: the NIR node,\n",
    "# so it is safe to pass onto nirtorch\n",
    "converted_module = nirtorch.nir_to_torch(nir_graph, nir_to_torch_map)\n",
    "converted_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a live example of this pattern in the NIR implementation for the [spiking neural network library Norse](https://github.com/norse/norse/blob/main/norse/torch/utils/import_nir.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
