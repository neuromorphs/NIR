{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lava-dl hdf5 export\n",
    "\n",
    "In order to test the export process, we used the [Oxford example](https://lava-nc.org/lava-lib-dl/slayer/notebooks/oxford/train.html) available in the LAVA-dl repository. Since this page is focused on NIR implementations, we are not covering the training aspects, but readers are welcome to visit the LAVA-dl documentation and train their own models. To facilitate the reproducibility of the tests, we copied a trained CUBALiF dense network into the NIR repository.\n",
    "\n",
    "It is important to mention that this `network.net` has been exported with the standard `hdf5` process in LAVA-dl, which takes the network blocks and saves them in this format.\n",
    "\n",
    "\n",
    "```\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "     ...\n",
    "     ...\n",
    "\n",
    "    def forward(self, spike):\n",
    "     ...\n",
    "     ...\n",
    "\n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))  \n",
    "```\n",
    "\n",
    "Although the standard is `hdf5`, the block structure is not compatible with NIR graphs, so the `lava_to_nir.py` functions are required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lava-dl to NIR\n",
    "\n",
    "Once we have the `hdf5` network from LAVA-dl, transforming it to a NIRgraph is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lava_to_nir as lava_to_nir\n",
    "\n",
    "lava_to_nir.convert_to_nir('network.net', 'network.nir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the network is compatible, it will generate the `network.nir` graph from the LAVA network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's happening inside?\n",
    "\n",
    "The first part of the function recursively inspects all layers in the LAVA graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_nir(net_config: PATH_TYPE, path: PATH_TYPE) -> nir.NIRGraph:\n",
    "    \"\"\"Load a NIR from a HDF/conn5 file.\"\"\"\n",
    "    with h5py.File(net_config, \"r\") as f:\n",
    "        nir_graph = read_node(f[\"layer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, it maps each node to a specific function. Notice that LAVA layers include both synapses and neurons. For example, a Dense layer consists of a dense synapse plus an array of neurons of any type. For that reason, the function reads LAVA layers and splits them into synapses and neurons according to NIR. At the moment, only CUBALiF neurons are mapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s dive into the CUBALiF neuron implementation. The main difference between NIR and LAVA is that NIR’s CUBALiF representation is continuous, while LAVA uses a discrete version of the dynamics to make it compatible with Loihi hardware. According to the [NIR2Lava script](https://github.com/neuromorphs/NIR/blob/main/paper/nir_to_lava.py), we decided to use `dt=1e-4` value by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important note is that LAVA-dl exports scaled hardware values to `hdf5`. However, to be more standard, we decided to export real floating-point values to NIR. This means we need to de-scale the current decay, voltage decay, and threshold values using the `scale` and ``weight_scale` factors (See [LAVA-dl CUBA-LiF](https://lava-nc.org/lava-lib-dl/slayer/neuron/neuron.html#module-lava.lib.dl.slayer.neuron.cuba)). By default, these values are `4096` and `64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lava-dl exports hardware fixed tipe to hdf5. For NIR, export in floating point. \n",
    "dt      = 1e-4  # This dt value is according to nir_to_lava.py script. https://github.com/neuromorphs/NIR/blob/main/paper/nir_to_lava.py#L67\n",
    "vdecay  = layer['neuron']['vDecay'][()]  / 4096 # Save the value in NIR as floating point\n",
    "idecay  = layer['neuron']['iDecay'][()]  / 4096 # Save the value in NIR as floating point\n",
    "thr     = layer['neuron']['vThMant'][()] / 64   # Save the value in NIR as floating point\n",
    "tau_mem = dt/float(vdecay) if vdecay != 0 else np.inf\n",
    "tau_syn = dt/float(idecay) if idecay != 0 else np.inf\n",
    "shape   = layer['weight'].shape[0]\n",
    "r       = tau_mem/dt # no scaling of synaptic current\n",
    "w_in    = tau_syn/dt # no scaling of synaptic voltage\n",
    "\n",
    "return nir.CubaLIF(\n",
    "    tau_syn=np.full(shape, tau_syn),\n",
    "    tau_mem=np.full(shape, tau_mem),\n",
    "    r=np.full(shape, r),  \n",
    "    v_leak=np.full(shape, 0.),  # currently no bias in Loihi's neurons\n",
    "    v_threshold=np.full(shape, thr),\n",
    "    w_in=np.full(shape,w_in),  \n",
    "    v_reset=np.full(shape,0.) # LAVA-DL CUBA LiF always reset to 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another difference between LAVA graphs and NIR graphs is the naming convention. LAVA uses `input_#` and `output_#` (where `#` is any number), while NIR uses only `input` and `output`. Moreover, to make it compatible with the `hdf5` standard, all strings need to be converted to bytes. The function `normalize_nir_graph()` performs this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_graph = normalize_nir_graph(nir_graph, to_bytes_in_edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exporting the NIR graph, it can be converted back to LAVA-dl and plotted to compare both implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nir\n",
    "from lib.nir_to_lava import ImportConfig, LavaLibrary, import_from_nir\n",
    "\n",
    "import_config = ImportConfig(library_preference=LavaLibrary.LavaDl)\n",
    "nir_graph = nir.read('/home/garciaal/neuromorphics/Trained/network.nir')\n",
    "nir_net = import_from_nir(nir_graph, import_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can use the DataLoader and the process in the [Oxford example](https://lava-nc.org/lava-lib-dl/slayer/notebooks/oxford/train.html) to generate the plots and compare them with the NIR network. The code below shows an example using the LAVA-dl tools, but the Oxford dataset is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lava.lib.dl.slayer as slayer\n",
    "from lava.lib.dl import netx\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lava_net = netx.hdf5.Network(net_config='/home/garciaal/neuromorphics/Trained/network.net')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "nir_net.to(device)\n",
    "lava_net.to(device)\n",
    "\n",
    "# Missing input dataset. Look for LAVA-dl examples\n",
    "output_lava = lava_net(input.to(device))\n",
    "output_nir = nir_net(input.to(device))\n",
    "event_nir = slayer.io.tensor_to_event(output_nir.cpu().data.numpy())\n",
    "event_lava = slayer.io.tensor_to_event(output_lava.cpu().data.numpy())\n",
    "\n",
    "# Calculate loss. This has to be 0\n",
    "error = slayer.loss.SpikeTime(time_constant=10, filter_order=2).to(device)\n",
    "loss_nir = error(output_nir, output_lava)\n",
    "print(f'nir loss to LAVA: {loss_nir}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```nir loss to LAVA: 0```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(200, 200))\n",
    "plt.plot(event_lava.t, event_lava.x, '.', markersize=12, label='lava network')\n",
    "plt.plot(event_nir.t, event_nir.x, '.', label='nir network')\n",
    "plt.xlabel('time [ms]')\n",
    "plt.ylabel('neuron')\n",
    "plt.legend()\n",
    "plt.savefig('nir_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename='nir_output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main limitations and things to improve\n",
    "\n",
    "1. Using `dt=1e-4` by default according to the `nir_to_lava.py` script. This needs to be confirmed with the LAVA developers.\n",
    "\n",
    "2. Only tested with 1D Dense CUBA LiF neurons. According to the code, more work is needed for 2D Dense layers.\n",
    "\n",
    "3. Different neuron types were not tested. Only CUBA LiF is implemented.\n",
    "\n",
    "4. Find a way to automate edge string correction. Currently, it is done manually:\n",
    "\n",
    "   ```\n",
    "   nir_graph.edges[3]=(b'input',0) \n",
    "   nir_graph.edges[4]=(3,b'output')\n",
    "   ```\n",
    "5. NIR graphs converted to LAVA-dl do not include delays when executing networks. Therefore, NIR-converted networks will generate an output without any network delay. Be careful when comparing with LAVA, since the loss may be different from 0 even if the plots look the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
