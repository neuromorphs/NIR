{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nir\n",
    "from lava_rnn import from_nir\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from snntorch import functional as SF\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found RNN subgraph, trying to parse\n",
      "detected subgraph! candidates: ['lif1']\n",
      "[warning] scaling weights to avoid scaling inputs, w_scale: 0.5\n",
      "w_in: 1.0, dt: 0.0001, tau_syn: 0.0002\n",
      "[warning] scaling weights to avoid scaling inputs, w_scale: 0.44999998807907104\n",
      "w_in: 1.0, dt: 0.0001, tau_syn: 0.0002222222281091009\n"
     ]
    }
   ],
   "source": [
    "nirgraph = nir.read('braille_v2.nir')\n",
    "net = from_nir(nirgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEVICE SETTINGS\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu:\n",
    "    gpu_sel = 1\n",
    "    device = torch.device(\"cuda:\"+str(gpu_sel))\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST DATA\n",
    "test_data_path = \"data/ds_test.pt\"\n",
    "ds_test = torch.load(test_data_path)\n",
    "\n",
    "letter_written = ['Space', 'A', 'E', 'I', 'O', 'U', 'Y']\n",
    "\n",
    "loss_fn = SF.ce_count_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test_loop(dataset, batch_size, net, loss_fn, device, shuffle=True, saved_state_dict=None, label_probabilities=False, regularization=None):\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    if saved_state_dict != None:\n",
    "        net.load_state_dict(saved_state_dict)\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "\n",
    "    for data, labels in loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        data = data.swapaxes(1, 2)  # NCT\n",
    "        spk_out, hid_rec = net(data)\n",
    "        spk_out = spk_out.moveaxis(2, 0)  # TCN\n",
    "\n",
    "        # Validation loss\n",
    "        if regularization != None:\n",
    "            # L1 loss on spikes per neuron from the hidden layer\n",
    "            reg_loss = regularization[0]*torch.mean(torch.sum(hid_rec, 0))\n",
    "            # L2 loss on total number of spikes from the hidden layer\n",
    "            reg_loss = reg_loss + regularization[1]*torch.mean(torch.sum(torch.sum(hid_rec, dim=0), dim=1)**2)\n",
    "            loss_val = loss_fn(spk_out, labels) + reg_loss\n",
    "        else:\n",
    "            loss_val = loss_fn(spk_out, labels)\n",
    "\n",
    "        batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "        # Accuracy\n",
    "        act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
    "        _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "        batch_acc.extend((neuron_max_act_total_out == labels).detach().cpu().numpy()) # batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "    \n",
    "    if label_probabilities:\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
    "        log_p_y = log_softmax_fn(act_total_out)\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
    "    else:\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 256]) torch.Size([64])\n",
      "torch.Size([256, 64, 7]) torch.Size([64])\n",
      "torch.Size([64, 12, 256]) torch.Size([64])\n",
      "torch.Size([256, 64, 7]) torch.Size([64])\n",
      "torch.Size([12, 12, 256]) torch.Size([12])\n",
      "torch.Size([256, 12, 7]) torch.Size([12])\n",
      "Test accuracy: 14.29%\n"
     ]
    }
   ],
   "source": [
    "### INFERENCE ON TEST SET\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "input_size = 12 \n",
    "num_steps = next(iter(ds_test))[0].shape[0]\n",
    "\n",
    "test_results = val_test_loop(ds_test, batch_size, net, loss_fn, device, shuffle=False, saved_state_dict=None, regularization=None)\n",
    "\n",
    "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
