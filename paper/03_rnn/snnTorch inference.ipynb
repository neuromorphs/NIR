{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a36e5c-e173-44f4-a26d-41146c88bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import snntorch\n",
    "import nirtorch\n",
    "from snntorch import import_nirtorch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc6de51-8cd1-4781-bad8-6876e9352e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST DATA\n",
    "test_data_path = \"data/ds_test.pt\"\n",
    "ds_test = torch.load(test_data_path)\n",
    "\n",
    "letter_written = ['Space', 'A', 'E', 'I', 'O', 'U', 'Y']\n",
    "device = \"cpu\"\n",
    "### LOSS FUNCTION\n",
    "loss_fn = torch.nn.functional.cross_entropy\n",
    "### OPTIMAL HYPERPARAMETERS\n",
    "parameters_path = \"data/parameters_ref_zero.json\"\n",
    "\n",
    "with open(parameters_path) as f:\n",
    "   parameters = json.load(f)\n",
    "\n",
    "import nir\n",
    "# nir_graph = nir.read(\"braille_retrained_zero.nir\")\n",
    "nir_graph = nir.read(\"braille_noDelay_bias_zero.nir\")\n",
    "# nir_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f65eb99-2ee0-42f6-b849-aa3781d553ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [type(x) for x in nir_graph.nodes.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10f6aff-6acd-461a-ac2a-c3da05b89a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphExecutor(\n",
       "  (fc1): Linear(in_features=12, out_features=38, bias=True)\n",
       "  (fc2): Linear(in_features=38, out_features=7, bias=True)\n",
       "  (input): Identity()\n",
       "  (lif2): Synaptic()\n",
       "  (output): Identity()\n",
       "  (lif1): RSynaptic(\n",
       "    (recurrent): Linear(in_features=38, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir_graph = nir.read(\"braille_noDelay_bias_zero.nir\")\n",
    "net = import_nirtorch.from_nir(nir_graph)\n",
    "net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405cc988-2b56-4e09-b617-5cbacf2a034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fc1', 'fc2', 'input', 'lif2', 'output', 'lif1'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir_graph.nodes.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024410b-8078-496e-b585-14e1f4ee49bb",
   "metadata": {},
   "source": [
    "# Save activity of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c101fe-dbce-4ed3-8a1c-f214c62b90db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RSynaptic' object has no attribute 'mem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/steve/Code/NIR/paper/03_rnn/snnTorch inference.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         lif1_out\u001b[39m.\u001b[39mappend(z)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(lif1_out)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m zero_out \u001b[39m=\u001b[39m record_layer1(\u001b[39m\"\u001b[39;49m\u001b[39mbraille_noDelay_bias_zero.nir\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m zero_out\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;32m/Users/steve/Code/NIR/paper/03_rnn/snnTorch inference.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lin_out):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     z, state \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mlif1(t, state)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     lif1_out\u001b[39m.\u001b[39mappend(z)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/steve/Code/NIR/paper/03_rnn/snnTorch%20inference.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(lif1_out)\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/Code/NIR/.newvenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Code/NIR/.newvenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/snntorch_fork/snntorch/_neurons/rsynaptic.py:314\u001b[0m, in \u001b[0;36mRSynaptic.forward\u001b[0;34m(self, input_, spk, syn, mem)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    308\u001b[0m     \u001b[39mhasattr\u001b[39m(spk, \u001b[39m\"\u001b[39m\u001b[39minit_flag\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(syn, \u001b[39m\"\u001b[39m\u001b[39minit_flag\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(mem, \u001b[39m\"\u001b[39m\u001b[39minit_flag\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m ):  \u001b[39m# only triggered on first-pass\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     spk, syn, mem \u001b[39m=\u001b[39m _SpikeTorchConv(spk, syn, mem, input_\u001b[39m=\u001b[39minput_)\n\u001b[1;32m    313\u001b[0m \u001b[39melif\u001b[39;00m mem \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmem, \u001b[39m\"\u001b[39m\u001b[39minit_flag\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m ):  \u001b[39m# init_hidden case\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspk, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msyn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem \u001b[39m=\u001b[39m _SpikeTorchConv(\n\u001b[1;32m    317\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspk, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msyn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem, input_\u001b[39m=\u001b[39minput_\n\u001b[1;32m    318\u001b[0m     )\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_hidden:\n",
      "File \u001b[0;32m~/Code/NIR/.newvenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RSynaptic' object has no attribute 'mem'"
     ]
    }
   ],
   "source": [
    "def record_layer1(graph):\n",
    "    net = import_nirtorch.from_nir(nir.read(graph))\n",
    "    lin_out = net.fc1(ds_test[0][0])\n",
    "    lin_out.shape\n",
    "    lif1_out = []\n",
    "    state = None\n",
    "    for i, t in enumerate(lin_out):\n",
    "        z, state = net.lif1(t, state)\n",
    "        lif1_out.append(z)\n",
    "    return torch.stack(lif1_out).detach()\n",
    "zero_out = record_layer1(\"braille_noDelay_bias_zero.nir\")\n",
    "zero_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b85720a-f790-4064-be3c-a7b893fd96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"snntorch_activity_zero.npy\", zero_out.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "863a8c00-03d6-4c0a-ba9f-53a28b5f72a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "record_layer1() got an unexpected keyword argument 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m subtract_out \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_layer1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbraille_subtract.nir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_subtract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m subtract_out\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorse_activity_subtract.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, zero_out\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mTypeError\u001b[0m: record_layer1() got an unexpected keyword argument 'dt'"
     ]
    }
   ],
   "source": [
    "subtract_out = record_layer1(\"braille_subtract.nir\", dt=1e-4, reset_method=norse.torch.functional.reset_subtract)\n",
    "subtract_out.shape\n",
    "np.save(\"snntorch_activity_subtract.npy\", zero_out.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8c56d73-aef4-4bcb-bc0c-0ba8ccc8d6f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RSynaptic' object has no attribute 'mem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# hid_rec = torch.stack(hid_rec)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spk_out, hid_rec\n\u001b[0;32m---> 12\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mT, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(net, data)\u001b[0m\n\u001b[1;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m----> 6\u001b[0m     z, state \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m      8\u001b[0m     hid_rec\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/nirtorch/nirtorch/from_nir.py:145\u001b[0m, in \u001b[0;36mGraphExecutor.forward\u001b[0;34m(self, data, old_state)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39melem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m out, new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mold_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst_node\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m new_state\u001b[38;5;241m.\u001b[39mcache[node\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    153\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/nirtorch/nirtorch/from_nir.py:118\u001b[0m, in \u001b[0;36mGraphExecutor._apply_module\u001b[0;34m(self, node, input_nodes, new_state, old_state, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(summed_inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     inputs\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mstack(summed_inputs)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 118\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# If the module is stateful, we know the output is (at least) a tuple\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# HACK to make it work for snnTorch\u001b[39;00m\n\u001b[1;32m    121\u001b[0m is_rsynaptic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnntorch._neurons.rsynaptic.RSynaptic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    122\u001b[0m     node\u001b[38;5;241m.\u001b[39melem\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    123\u001b[0m )\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/snntorch/snntorch/_neurons/rsynaptic.py:314\u001b[0m, in \u001b[0;36mRSynaptic.forward\u001b[0;34m(self, input_, spk, syn, mem)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(spk, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(syn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(mem, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m ):  \u001b[38;5;66;03m# only triggered on first-pass\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     spk, syn, mem \u001b[38;5;241m=\u001b[39m _SpikeTorchConv(spk, syn, mem, input_\u001b[38;5;241m=\u001b[39minput_)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m ):  \u001b[38;5;66;03m# init_hidden case\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem \u001b[38;5;241m=\u001b[39m _SpikeTorchConv(\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem, input_\u001b[38;5;241m=\u001b[39minput_\n\u001b[1;32m    318\u001b[0m     )\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden:\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RSynaptic' object has no attribute 'mem'"
     ]
    }
   ],
   "source": [
    "def apply(net, data):\n",
    "    state = None\n",
    "    hid_rec = []\n",
    "    out = []\n",
    "    for i, t in enumerate(data):\n",
    "        z, state = net(t, state)\n",
    "        out.append(z)\n",
    "        hid_rec.append(state)\n",
    "    spk_out = torch.stack(out)\n",
    "    # hid_rec = torch.stack(hid_rec)\n",
    "    return spk_out, hid_rec\n",
    "plt.imshow(apply(net, ds_test[0][0])[0].detach().T, aspect=5, interpolation=\"none\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251db4e6-841a-4878-8135-840628b058ce",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0652cd-4f57-4988-a626-88a340a4a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test_loop(dataset, batch_size, net, loss_fn, device, shuffle=True, saved_state_dict=None, label_probabilities=False, regularization=None):\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    if saved_state_dict != None:\n",
    "        net.load_state_dict(saved_state_dict)\n",
    "    net.eval()\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "\n",
    "    for data, labels in loader:\n",
    "        data = data.to(device).swapaxes(1, 0)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        spk_out, hid_rec = apply(net, data)\n",
    "\n",
    "        # Validation loss\n",
    "        if regularization != None:\n",
    "            # L1 loss on spikes per neuron from the hidden layer\n",
    "            reg_loss = regularization[0]*torch.mean(torch.sum(hid_rec, 0))\n",
    "            # L2 loss on total number of spikes from the hidden layer\n",
    "            reg_loss = reg_loss + regularization[1]*torch.mean(torch.sum(torch.sum(hid_rec, dim=0), dim=1)**2)\n",
    "            loss_val = loss_fn(spk_out, labels) + reg_loss\n",
    "        else:\n",
    "            loss_val = loss_fn(spk_out.sum(0), labels)\n",
    "\n",
    "        batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "        # Accuracy\n",
    "        act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
    "        _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "        batch_acc.extend((neuron_max_act_total_out == labels).detach().cpu().numpy()) # batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "    \n",
    "    if label_probabilities:\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
    "        log_p_y = log_softmax_fn(act_total_out)\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
    "    else:\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d083db-7860-4332-ad11-cf9276406226",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INFERENCE ON TEST SET\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "input_size = 12 \n",
    "num_steps = next(iter(ds_test))[0].shape[0]\n",
    "regularization = [parameters[\"reg_l1\"], parameters[\"reg_l2\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9b252a-05e6-4943-8f79-fe2059281871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_val(graph):\n",
    "    net = #norse.torch.from_nir(graph, reset_method=reset_method)\n",
    "    return val_test_loop(ds_test, batch_size, net, loss_fn, device, shuffle=False)#, regularization=regularization)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4c4fb1-a425-4164-b86f-6d47bb343a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 18.57%\n"
     ]
    }
   ],
   "source": [
    "test_results = load_and_val(\"braille_subtract.nir\")\n",
    "np.save(\"snntorch_accuracy_subtract.npy\", np.round(test_results[1]*100,2))\n",
    "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262a74e4-f972-4516-a5ad-8680b77d09e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 12.86%\n"
     ]
    }
   ],
   "source": [
    "test_results = load_and_val(\"braille_retrained_zero.nir\", reset_method=norse.torch.functional.reset_value)\n",
    "np.save(\"snntorch_accuracy_zero.npy\", np.round(test_results[1]*100,2))\n",
    "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
