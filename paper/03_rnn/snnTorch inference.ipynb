{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a36e5c-e173-44f4-a26d-41146c88bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import snntorch\n",
    "from snntorch import import_nirtorch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc6de51-8cd1-4781-bad8-6876e9352e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NIRGraph(nodes={'fc1': Affine(weight=array([[-1.33806360e+00,  5.79449013e-02,  1.56500041e-01,\n",
       "        -8.98946896e-02,  4.30168718e-01, -1.13412477e-01,\n",
       "        -4.90320265e-01,  3.49327892e-01,  6.17891490e-01,\n",
       "         6.52276158e-01,  2.66522588e-03, -2.09836102e+00],\n",
       "       [-1.25033751e-01, -2.51833767e-01, -1.79891467e-01,\n",
       "        -3.23751152e-01, -1.48391396e-01, -2.94398308e-01,\n",
       "        -4.33553278e-01, -2.49562204e-01, -3.03823799e-01,\n",
       "        -1.69630110e-01, -3.65726292e-01, -5.70847355e-02],\n",
       "       [-5.70042276e+00, -1.43848926e-01, -6.42502487e-01,\n",
       "         8.02832842e-02,  1.93597808e-01, -2.70732808e+00,\n",
       "        -1.05163224e-01,  5.95107488e-02,  1.37910172e-02,\n",
       "        -4.96907711e+00, -1.19294591e-01, -3.27644974e-01],\n",
       "       [-1.87006846e-01, -3.03020142e-02, -2.01153517e-01,\n",
       "        -3.32092166e-01, -1.75986573e-01, -3.54239196e-01,\n",
       "        -1.41495883e-01,  8.16067122e-03, -7.10058063e-02,\n",
       "        -4.07845587e-01, -7.35815167e-02, -1.37334466e-01],\n",
       "       [-3.89165252e-01, -7.77807355e-01, -8.88431489e-01,\n",
       "        -6.06048286e-01, -8.65095019e-01, -2.17358813e-01,\n",
       "        -3.57659429e-01, -3.58444512e-01, -3.82805288e-01,\n",
       "        -7.81289577e-01, -2.59731889e-01, -7.12280512e-01],\n",
       "       [-2.80733883e-01, -6.95838809e-01,  1.70007080e-01,\n",
       "        -6.54830277e-01, -4.39952254e-01, -4.92904544e-01,\n",
       "         1.15529783e-01, -6.53500497e-01, -4.12710190e-01,\n",
       "        -3.90246958e-01,  7.37435445e-02, -2.07325250e-01],\n",
       "       [ 1.09707020e-01, -4.88075882e-01, -5.10403097e-01,\n",
       "        -5.08627892e-01, -4.05520499e-01, -8.80334228e-02,\n",
       "        -1.36689544e-01,  1.24175310e-01, -2.89912313e-01,\n",
       "        -3.44300598e-01, -1.02866672e-01, -2.40609795e-01],\n",
       "       [-3.37909728e-01, -8.86154234e-01, -5.10360181e-01,\n",
       "        -1.03676271e+00, -8.16740990e-01, -6.88886762e-01,\n",
       "        -7.59899557e-01, -9.18971300e-01, -2.00340003e-02,\n",
       "         4.46751863e-01, -9.78530884e-01, -6.14381075e-01],\n",
       "       [-1.57809809e-01, -7.90821731e-01, -6.68783307e-01,\n",
       "        -1.36281681e+00, -9.63540912e-01, -7.53566742e-01,\n",
       "        -5.89352250e-01, -1.37870252e+00, -1.23513341e+00,\n",
       "        -1.18952858e+00, -8.95347714e-01, -9.65668917e-01],\n",
       "       [-1.43896139e+00, -1.52550840e+00, -1.03107071e+00,\n",
       "        -1.00304341e+00, -1.35011292e+00, -1.80872726e+00,\n",
       "        -1.39558578e+00, -1.56432664e+00, -1.82470620e+00,\n",
       "        -1.71663594e+00, -1.62700081e+00, -7.85533547e-01],\n",
       "       [-1.47900879e+00,  2.76133686e-01,  9.50337276e-02,\n",
       "         1.77351281e-01, -4.20129180e-01,  8.29435810e-02,\n",
       "         1.54030263e-01, -5.40620871e-02, -2.21945375e-01,\n",
       "         5.13108894e-02,  9.54460949e-02, -1.17873885e-01],\n",
       "       [-1.93058503e+00, -2.55504161e-01, -5.44016063e-01,\n",
       "        -8.16175163e-01, -1.46471429e+00, -1.27867007e+00,\n",
       "        -3.10512215e-01, -1.03095531e+00, -8.03308129e-01,\n",
       "        -2.14875984e+00, -1.60597205e-01, -1.51909733e+00],\n",
       "       [-2.99119174e-01, -2.15384364e-01, -1.68948516e-01,\n",
       "        -6.66171908e-02, -6.29725605e-02, -4.49712247e-01,\n",
       "        -2.00051591e-01, -4.21856552e-01, -3.14226449e-01,\n",
       "        -3.78025204e-01, -1.02930948e-01, -5.02009809e-01],\n",
       "       [-2.10412871e-02, -1.82768062e-01, -2.18057185e-01,\n",
       "        -3.82992506e-01, -6.81143031e-02, -1.99890077e-01,\n",
       "        -2.54382938e-01, -5.26665330e-01, -3.23767424e-01,\n",
       "        -3.36428165e-01, -4.02161330e-01,  7.91241378e-02],\n",
       "       [ 4.89587933e-01, -3.09049666e-01, -2.17858285e-01,\n",
       "         1.38935566e-01,  5.74820442e-04,  3.44366491e-01,\n",
       "         5.97355217e-02, -2.23792657e-01, -2.89876294e+00,\n",
       "        -5.83746791e-01,  2.30763614e-01, -1.75406289e+00],\n",
       "       [-1.67782575e-01, -1.71046868e-01, -2.28867367e-01,\n",
       "        -3.80339533e-01, -1.31916061e-01, -2.18923777e-01,\n",
       "        -2.23293528e-01, -3.36520463e-01, -2.17544630e-01,\n",
       "        -2.38023829e-02, -3.18915725e-01, -2.43919477e-01],\n",
       "       [-1.98335454e-01, -5.65262958e-02, -3.02673548e-01,\n",
       "        -3.43527287e-01, -3.03577483e-01, -3.07988226e-01,\n",
       "        -1.78837419e-01, -2.76840389e-01, -5.24723887e-01,\n",
       "        -3.33370268e-01, -7.27637112e-02, -2.15234056e-01],\n",
       "       [-2.48528749e-01, -4.87185538e-01, -4.62004513e-01,\n",
       "        -5.87023854e-01, -3.55446786e-01, -2.29909971e-01,\n",
       "        -9.18241218e-02, -1.94788128e-01, -5.26123822e-01,\n",
       "        -3.25814337e-01, -3.43620956e-01,  6.92038685e-02],\n",
       "       [-4.12495285e-01, -1.00081718e+00, -8.20530713e-01,\n",
       "        -1.02486420e+00, -1.08320272e+00, -5.69324017e-01,\n",
       "        -1.22831094e+00, -9.94262040e-01, -1.04446161e+00,\n",
       "        -1.48602813e-01, -4.25199658e-01, -3.29810560e-01],\n",
       "       [ 6.51329905e-02, -7.01327264e-01, -1.94168910e-01,\n",
       "        -1.56907797e-01,  1.83522806e-01, -8.03050771e-02,\n",
       "         6.12714171e-01, -6.46732211e-01, -6.26059413e-01,\n",
       "         3.91810656e-01, -5.22614241e-01, -1.39083052e+00],\n",
       "       [-4.25576717e-02, -6.99033022e-01, -5.95435560e-01,\n",
       "        -6.46161497e-01, -3.92969906e-01, -7.99652874e-01,\n",
       "        -8.94161642e-01, -2.50139892e-01, -1.73515558e-01,\n",
       "         1.98485523e-01, -5.63344181e-01, -4.03504729e-01],\n",
       "       [-8.92806053e-01, -1.07555974e+00, -1.15103781e+00,\n",
       "        -1.20196307e+00, -7.61805892e-01, -1.13761497e+00,\n",
       "        -6.77022040e-01, -6.37903512e-01, -4.67487395e-01,\n",
       "        -1.36628830e+00, -7.07919896e-01, -1.14591026e+00],\n",
       "       [-2.98514038e-01, -1.77238975e-02, -3.45220566e-01,\n",
       "        -3.94071341e-01, -4.93472517e-01, -8.48213255e-01,\n",
       "        -1.04900934e-01, -9.15017903e-01, -1.46017224e-01,\n",
       "         2.07692366e-02, -3.39710824e-02, -5.29420197e-01],\n",
       "       [-5.32559395e-01, -1.29362047e-01, -3.10092028e-02,\n",
       "        -4.90021497e-01, -3.08258325e-01, -4.48949039e-01,\n",
       "        -1.89774379e-01, -3.67669851e-01, -4.79271144e-01,\n",
       "        -8.81483495e-01, -4.90492731e-01,  6.67327195e-02],\n",
       "       [-3.18091989e-01, -6.00261450e-01, -5.24344921e-01,\n",
       "        -8.71350348e-01, -8.27224135e-01, -1.22709990e+00,\n",
       "        -2.11906329e-01, -9.83488321e-01, -9.48330283e-01,\n",
       "        -1.31354868e+00, -5.51942945e-01, -6.79549277e-01],\n",
       "       [-1.59072983e+00,  6.39110580e-02,  3.10338825e-01,\n",
       "         1.27224743e-01, -1.27319843e-01,  7.34639987e-02,\n",
       "        -4.19698060e-02, -2.36622953e+00, -2.00210905e+00,\n",
       "        -3.45514417e-01, -3.21853980e-02,  2.18193546e-01],\n",
       "       [-4.73522931e-01, -1.47565991e-01,  1.96338966e-02,\n",
       "        -2.05682606e-01, -8.88952985e-02, -2.91107479e-03,\n",
       "        -3.04047167e-01, -2.28016809e-01, -4.14249480e-01,\n",
       "        -2.19156757e-01, -4.57372330e-02, -9.91667435e-02],\n",
       "       [ 1.03931952e+00,  1.33317649e-01, -9.19901848e-01,\n",
       "         3.75295095e-02, -4.87037867e-01, -4.34297144e-01,\n",
       "         7.99190640e-01, -1.96453199e-01,  1.09256089e-01,\n",
       "        -1.16803181e+00, -3.19875479e-01, -9.96015370e-01],\n",
       "       [-1.03998709e+00, -7.89335728e-01, -1.04350841e+00,\n",
       "        -1.04313231e+00, -1.04613113e+00, -1.07667410e+00,\n",
       "        -1.23014545e+00, -1.31846321e+00, -7.91515231e-01,\n",
       "         2.47034803e-02, -5.02733290e-01, -1.10817313e+00],\n",
       "       [-4.19288844e-01, -1.18757956e-01, -1.25219971e-01,\n",
       "        -6.75438121e-02, -3.22077200e-02, -2.62635443e-02,\n",
       "        -4.83912230e-01, -2.34307200e-01, -9.45965201e-02,\n",
       "        -3.14280361e-01, -3.87790918e-01, -5.40695079e-02],\n",
       "       [-1.45467722e+00, -1.01368022e+00, -1.13531697e+00,\n",
       "        -8.53952050e-01, -7.26027727e-01, -9.73501682e-01,\n",
       "        -4.85849082e-01, -1.21330452e+00, -1.36303306e+00,\n",
       "        -1.17418325e+00, -2.09765241e-01, -5.20555317e-01],\n",
       "       [-3.74049187e-01, -3.79080415e-01, -4.84512925e-01,\n",
       "        -4.39419955e-01, -2.02977598e-01, -1.46932378e-01,\n",
       "        -7.51340389e-02, -5.73772132e-01, -6.31351620e-02,\n",
       "        -4.59063679e-01, -1.89911112e-01,  4.00237069e-02],\n",
       "       [ 6.40019596e-01,  3.27513129e-01, -4.84064192e-01,\n",
       "        -1.42701298e-01, -6.77896857e-01, -1.51411247e+00,\n",
       "        -1.40037760e-01, -5.35719931e-01,  1.46131620e-01,\n",
       "         2.13328260e-03, -1.12650655e-01,  1.42224833e-01],\n",
       "       [-2.29771286e-01,  2.68660560e-02, -1.37913182e-01,\n",
       "        -1.07423043e+00,  3.57274450e-02,  9.57883075e-02,\n",
       "         2.39299729e-01, -4.34778512e-01, -1.94756973e+00,\n",
       "        -2.98364967e-01, -1.02140673e-01,  1.29150031e-02],\n",
       "       [-3.73703063e-01, -1.76398665e-01, -2.91334391e-01,\n",
       "        -3.65110725e-01,  5.97435012e-02, -1.69721976e-01,\n",
       "        -8.71117562e-02, -3.68352592e-01, -1.82826549e-01,\n",
       "         8.06496516e-02, -4.36735392e-01, -3.93962175e-01],\n",
       "       [-1.91376925e-01, -4.45704818e-01, -5.30195713e-01,\n",
       "        -1.06916629e-01, -1.15229338e-02, -2.67380863e-01,\n",
       "        -3.92353207e-01, -5.88905096e-01, -3.08191955e-01,\n",
       "        -4.78448644e-02, -9.96246710e-02, -1.95133597e-01],\n",
       "       [-4.03351009e-01, -1.46373175e-02, -3.93006474e-01,\n",
       "        -6.09387644e-02, -3.20818931e-01, -1.77159578e-01,\n",
       "        -2.09433720e-01, -2.34537244e-01, -3.51223081e-01,\n",
       "        -2.20073476e-01, -1.90035984e-01, -1.75166145e-01],\n",
       "       [ 4.58754510e-01, -2.48341128e-01, -5.28651297e-01,\n",
       "         2.17981651e-01,  3.95329177e-01,  2.58911282e-01,\n",
       "         4.92601059e-02, -2.49467850e-01,  3.27140927e-01,\n",
       "        -6.22521162e-01, -2.41364121e-01, -5.83322253e-04]], dtype=float32), bias=array([-0.06660467, -0.06271385,  0.11628828, -0.47137752, -0.67314875,\n",
       "       -0.02388418, -0.1922105 , -1.0749255 , -0.63263166, -1.6948543 ,\n",
       "       -0.19495536, -0.9371866 , -0.02987791, -0.07024019,  0.2161934 ,\n",
       "       -0.14119804, -0.06701948, -0.3532523 , -1.3149959 ,  0.17989857,\n",
       "       -0.6817015 , -1.4427202 , -0.46345255, -0.18932961, -0.3266655 ,\n",
       "        0.01361324, -0.4382786 ,  0.041508  , -1.2569448 , -0.42146248,\n",
       "       -0.6470624 , -0.38310012,  0.15982991,  0.2514669 , -0.197068  ,\n",
       "       -0.23724592, -0.13078815,  0.06192012], dtype=float32)), 'fc2': Affine(weight=array([[-5.06838858e-01, -1.07892882e-02, -4.19766188e-01,\n",
       "         1.44365326e-01,  3.36338803e-02,  1.30761722e-02,\n",
       "         9.56356823e-02,  1.11434702e-02,  8.96422490e-02,\n",
       "        -5.02961949e-02, -2.86624384e+00, -3.50401700e-02,\n",
       "        -5.77204041e-02,  5.97732887e-02, -7.96933591e-01,\n",
       "         4.15196605e-02,  9.27986801e-02, -2.87220050e-02,\n",
       "        -9.88141969e-02, -1.39560804e-01, -1.92515198e-02,\n",
       "         6.35946319e-02, -1.46376401e-01, -8.92415759e-04,\n",
       "        -5.77394329e-02, -6.93116426e+00,  6.21942915e-02,\n",
       "        -2.82156301e+00, -8.39206576e-03, -1.14782117e-01,\n",
       "        -4.11095023e-02,  9.77700669e-03,  1.74672976e-01,\n",
       "         7.13832602e-02,  1.56383682e-02, -4.17738557e-02,\n",
       "        -8.42593983e-02,  5.58709383e-01],\n",
       "       [-1.12398326e+00, -1.50322154e-01,  1.64004922e+00,\n",
       "        -2.82070320e-02, -6.05120063e-02,  6.79648876e-01,\n",
       "         2.90618893e-02, -9.38328877e-02,  1.42664835e-01,\n",
       "        -9.45669189e-02,  1.22259408e-01,  2.96613593e-02,\n",
       "        -3.37121189e-02, -1.33561447e-01,  1.43926710e-01,\n",
       "         1.67447940e-01,  1.95828900e-01,  1.45389974e-01,\n",
       "        -1.57789186e-01,  9.13904533e-02, -1.16598256e-01,\n",
       "        -1.45101532e-01, -2.92760208e-02, -9.29184854e-02,\n",
       "         1.18927009e-01,  1.08972144e+00,  8.36604610e-02,\n",
       "        -1.62712061e+00, -1.22851580e-01, -4.03985493e-02,\n",
       "         1.19819991e-01,  7.24379793e-02,  7.20614254e-01,\n",
       "         3.81762356e-01,  2.01225936e-01,  5.60850911e-02,\n",
       "        -7.82585517e-02, -1.30892050e+00],\n",
       "       [ 3.74878608e-02, -1.70476884e-01, -8.21259081e-01,\n",
       "        -1.51602402e-02,  2.54815891e-02,  1.24525568e-02,\n",
       "        -1.21602401e-01, -1.95372388e-01,  2.33759414e-02,\n",
       "        -1.85447186e-02,  1.66169241e-01, -1.45844407e-02,\n",
       "         1.04141101e-01, -1.77643970e-02,  6.03502572e-01,\n",
       "        -1.27778873e-01,  4.34587300e-02,  1.99867617e-02,\n",
       "        -1.24794476e-01,  2.03898966e-01, -2.03904003e-01,\n",
       "         9.21404809e-02, -9.00797918e-03,  2.58355159e-02,\n",
       "         4.64039184e-02,  3.62422973e-01,  4.94936034e-02,\n",
       "         1.75203994e-01, -1.26607075e-01,  8.02723169e-02,\n",
       "        -3.94111574e-02, -5.01431078e-02,  4.96017262e-02,\n",
       "         4.70454395e-01, -1.03597961e-01, -1.44620806e-01,\n",
       "         7.48398006e-02, -1.69576079e-01],\n",
       "       [ 4.33884889e-01, -1.14651201e-02,  6.64373159e-01,\n",
       "         1.70359462e-01, -2.16643307e-02, -1.47362620e-01,\n",
       "         1.08263269e-01, -2.59950012e-02,  1.23204039e-02,\n",
       "        -1.42493367e-01,  5.31777382e-01, -6.14346564e-03,\n",
       "         2.85224169e-02, -7.73465112e-02,  1.16948716e-01,\n",
       "         1.18798152e-01,  3.89430709e-02,  1.76851228e-01,\n",
       "        -7.03656301e-02,  3.82632107e-01,  3.31779160e-02,\n",
       "         3.35594453e-02,  4.53297161e-02,  8.76254067e-02,\n",
       "         2.65288293e-01,  5.22843786e-02,  1.66870207e-01,\n",
       "         4.60372448e-01,  4.58758622e-02,  9.12196860e-02,\n",
       "         1.15313232e-01,  1.51316104e-02,  3.24849188e-01,\n",
       "        -3.36522795e-02,  1.20847709e-01, -3.48761454e-02,\n",
       "         1.49899766e-01, -6.27557158e-01],\n",
       "       [ 5.09265542e-01,  7.08498433e-02,  6.38753846e-02,\n",
       "        -1.87460668e-02, -1.30572051e-01,  8.98270980e-02,\n",
       "        -9.37704369e-02,  7.18014091e-02,  1.10340282e-01,\n",
       "        -1.51600063e-01,  3.82006675e-01, -2.75978297e-02,\n",
       "         1.12724908e-01, -1.16297998e-01,  7.52552673e-02,\n",
       "         9.28755626e-02,  7.56508559e-02,  1.37253001e-01,\n",
       "        -4.92466148e-03, -1.01923335e+00,  8.64728764e-02,\n",
       "         4.18691486e-02,  8.91382049e-04, -1.51977077e-01,\n",
       "        -1.03046738e-01,  3.17345262e-01,  1.44714594e-01,\n",
       "         7.19286427e-02,  1.21015266e-01,  9.54369828e-02,\n",
       "        -1.17486887e-01, -9.70561430e-02, -2.65173823e-01,\n",
       "        -3.77561837e-01,  1.16768785e-01,  2.07734853e-02,\n",
       "         1.10333107e-01,  3.98689657e-01],\n",
       "       [-7.66712487e-01,  3.24096121e-02, -1.41903174e+00,\n",
       "         1.66090444e-01,  8.26327503e-02, -9.37422514e-02,\n",
       "         5.23514226e-02, -5.93011789e-02,  1.17303148e-01,\n",
       "        -6.54332638e-02,  2.47840092e-01,  4.42931205e-02,\n",
       "        -1.18544050e-01,  7.85725713e-02,  9.62167792e-03,\n",
       "        -2.71108523e-02,  8.35769344e-03, -1.23733558e-01,\n",
       "         8.64824355e-02, -4.19672132e-01,  7.37093762e-03,\n",
       "         7.00855106e-02, -2.35766277e-01,  2.65210215e-02,\n",
       "        -4.77117896e-02, -1.57707050e-01,  4.64529954e-02,\n",
       "        -2.13805020e-01,  7.40359873e-02,  4.08489518e-02,\n",
       "         6.08380251e-02,  2.12883428e-02,  9.41646285e-03,\n",
       "         4.46303010e-01,  2.07880102e-02, -5.00804093e-03,\n",
       "         3.36484350e-02,  3.32374901e-01],\n",
       "       [-5.66859722e-01,  3.80514301e-02,  5.53188562e-01,\n",
       "         1.03382573e-01,  3.37247998e-02, -9.43999812e-02,\n",
       "        -8.94442201e-03,  3.00731603e-02, -5.00299521e-02,\n",
       "         1.30902067e-01,  2.49211594e-01,  4.90401834e-02,\n",
       "        -1.23352058e-01, -7.62403458e-02, -8.74632955e-01,\n",
       "         5.37457913e-02,  9.19905975e-02,  1.43567761e-02,\n",
       "         4.04033053e-04, -9.11519751e-02, -2.04086639e-02,\n",
       "         7.60384556e-03,  2.22885720e-02,  1.09277219e-01,\n",
       "         3.71923968e-02,  1.70244515e-01, -2.46176645e-02,\n",
       "         1.13821852e+00, -2.57511735e-02, -1.53648138e-01,\n",
       "         1.27495443e-02, -1.01792052e-01,  1.74445540e-01,\n",
       "        -2.38826737e-01, -1.33167028e-01, -1.13680080e-01,\n",
       "        -7.95657374e-03,  1.19234696e-01]], dtype=float32), bias=array([0.35732532, 0.25837114, 0.2918961 , 0.25666502, 0.26860565,\n",
       "       0.32621846, 0.31571466], dtype=float32)), 'input': Input(input_type={'input': array([12])}), 'lif1.lif': CubaLIF(tau_syn=array([0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222, 0.00022222]), tau_mem=array([0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001]), r=array([9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762, 9.99999762, 9.99999762,\n",
       "       9.99999762, 9.99999762, 9.99999762]), v_leak=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0.]), v_threshold=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1.]), w_in=array([2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228, 2.22222228])), 'lif1.w_rec': Affine(weight=array([[-4.73091096e-01, -2.38821395e-02, -1.21450734e+00, ...,\n",
       "        -2.55327709e-02,  2.93923984e-03,  2.46071219e-01],\n",
       "       [-9.17187035e-02,  1.08270817e-01, -9.25179064e-01, ...,\n",
       "        -1.16732784e-01, -1.70501053e-01, -4.79167432e-01],\n",
       "       [-1.57320881e+00, -2.04725340e-01,  3.60397905e-01, ...,\n",
       "        -1.96033657e-01, -1.35500193e-01, -4.46652222e+00],\n",
       "       ...,\n",
       "       [ 3.35712135e-02, -5.95304593e-02, -7.54801989e-01, ...,\n",
       "         7.58048967e-02,  4.62220870e-02, -5.95571935e-01],\n",
       "       [ 5.69576537e-03,  1.35611981e-01, -9.78484094e-01, ...,\n",
       "        -7.17893913e-02,  1.04019225e-01, -8.28207314e-01],\n",
       "       [-4.56872851e-01, -5.70783764e-02,  6.76585585e-02, ...,\n",
       "        -6.91005364e-02,  1.81561723e-01, -7.86839187e-01]], dtype=float32), bias=array([ 0.1316501 , -0.31533462,  0.20473164, -0.3833598 , -0.55025274,\n",
       "       -0.07363562, -0.28082493, -0.76008654, -0.8950184 , -1.6780374 ,\n",
       "        0.2015842 , -0.87692475, -0.42520833, -0.3249473 , -0.0942375 ,\n",
       "       -0.33284816, -0.39378524, -0.2560812 , -1.2957476 ,  0.04879909,\n",
       "       -0.43744928, -1.216738  , -0.34971476, -0.22618333, -0.52279735,\n",
       "        0.09483434, -0.33678243, -0.10701751, -1.172679  , -0.07315169,\n",
       "       -0.8246845 , -0.27778238,  0.00822892, -0.04202311, -0.37068278,\n",
       "       -0.44650677, -0.25702837,  0.11530228], dtype=float32)), 'lif2': CubaLIF(tau_syn=array([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002]), tau_mem=array([0.00022222, 0.00022222, 0.00022222, 0.00022222, 0.00022222,\n",
       "       0.00022222, 0.00022222]), r=array([2.22222228, 2.22222228, 2.22222228, 2.22222228, 2.22222228,\n",
       "       2.22222228, 2.22222228]), v_leak=array([0., 0., 0., 0., 0., 0., 0.]), v_threshold=array([1., 1., 1., 1., 1., 1., 1.]), w_in=array([2., 2., 2., 2., 2., 2., 2.])), 'output': Output(output_type={'output': array([7])})}, edges=[('lif1.w_rec', 'lif1.lif'), ('lif2', 'output'), ('fc2', 'lif2'), ('input', 'fc1'), ('lif1.lif', 'lif1.w_rec'), ('fc1', 'lif1.lif'), ('lif1.lif', 'fc2')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST DATA\n",
    "test_data_path = \"data/ds_test.pt\"\n",
    "ds_test = torch.load(test_data_path)\n",
    "\n",
    "letter_written = ['Space', 'A', 'E', 'I', 'O', 'U', 'Y']\n",
    "device = \"cpu\"\n",
    "### LOSS FUNCTION\n",
    "loss_fn = torch.nn.functional.cross_entropy\n",
    "### OPTIMAL HYPERPARAMETERS\n",
    "parameters_path = \"data/parameters_ref_zero.json\"\n",
    "\n",
    "with open(parameters_path) as f:\n",
    "   parameters = json.load(f)\n",
    "\n",
    "import nir\n",
    "nir_graph = nir.read(\"braille_retrained_zero.nir\")\n",
    "nir_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f65eb99-2ee0-42f6-b849-aa3781d553ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nir.ir.Affine,\n",
       " nir.ir.Affine,\n",
       " nir.ir.Input,\n",
       " nir.ir.CubaLIF,\n",
       " nir.ir.Affine,\n",
       " nir.ir.CubaLIF,\n",
       " nir.ir.Output]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(x) for x in nir_graph.nodes.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10f6aff-6acd-461a-ac2a-c3da05b89a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphExecutor(\n",
       "  (fc1): Linear(in_features=12, out_features=38, bias=True)\n",
       "  (fc2): Linear(in_features=38, out_features=7, bias=True)\n",
       "  (input): Identity()\n",
       "  (lif2): Synaptic()\n",
       "  (output): Identity()\n",
       "  (lif1): RSynaptic(\n",
       "    (recurrent): Linear(in_features=38, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = import_nirtorch.from_nir(nir_graph)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "405cc988-2b56-4e09-b617-5cbacf2a034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fc1', 'fc2', 'input', 'lif2', 'output', 'lif1'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir_graph.nodes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024410b-8078-496e-b585-14e1f4ee49bb",
   "metadata": {},
   "source": [
    "# Save activity of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c101fe-dbce-4ed3-8a1c-f214c62b90db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RSynaptic' object has no attribute 'mem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m         lif1_out\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(lif1_out)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 11\u001b[0m zero_out \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_layer1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbraille_zero.nir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m zero_out\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mrecord_layer1\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m      6\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lin_out):\n\u001b[0;32m----> 8\u001b[0m     z, state \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlif1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     lif1_out\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(lif1_out)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/snntorch/snntorch/_neurons/rsynaptic.py:314\u001b[0m, in \u001b[0;36mRSynaptic.forward\u001b[0;34m(self, input_, spk, syn, mem)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(spk, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(syn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(mem, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m ):  \u001b[38;5;66;03m# only triggered on first-pass\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     spk, syn, mem \u001b[38;5;241m=\u001b[39m _SpikeTorchConv(spk, syn, mem, input_\u001b[38;5;241m=\u001b[39minput_)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m ):  \u001b[38;5;66;03m# init_hidden case\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem \u001b[38;5;241m=\u001b[39m _SpikeTorchConv(\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem, input_\u001b[38;5;241m=\u001b[39minput_\n\u001b[1;32m    318\u001b[0m     )\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden:\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RSynaptic' object has no attribute 'mem'"
     ]
    }
   ],
   "source": [
    "def record_layer1(graph):\n",
    "    net = import_nirtorch.from_nir(nir.read(graph))\n",
    "    lin_out = net.fc1(ds_test[0][0])\n",
    "    lin_out.shape\n",
    "    lif1_out = []\n",
    "    state = None\n",
    "    for i, t in enumerate(lin_out):\n",
    "        z, state = net.lif1(t, state)\n",
    "        lif1_out.append(z)\n",
    "    return torch.stack(lif1_out).detach()\n",
    "zero_out = record_layer1(\"braille_zero.nir\")\n",
    "zero_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b85720a-f790-4064-be3c-a7b893fd96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"snntorch_activity_zero.npy\", zero_out.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "863a8c00-03d6-4c0a-ba9f-53a28b5f72a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "record_layer1() got an unexpected keyword argument 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m subtract_out \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_layer1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbraille_subtract.nir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_subtract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m subtract_out\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorse_activity_subtract.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, zero_out\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mTypeError\u001b[0m: record_layer1() got an unexpected keyword argument 'dt'"
     ]
    }
   ],
   "source": [
    "subtract_out = record_layer1(\"braille_subtract.nir\", dt=1e-4, reset_method=norse.torch.functional.reset_subtract)\n",
    "subtract_out.shape\n",
    "np.save(\"snntorch_activity_subtract.npy\", zero_out.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8c56d73-aef4-4bcb-bc0c-0ba8ccc8d6f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RSynaptic' object has no attribute 'mem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# hid_rec = torch.stack(hid_rec)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spk_out, hid_rec\n\u001b[0;32m---> 12\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mT, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(net, data)\u001b[0m\n\u001b[1;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m----> 6\u001b[0m     z, state \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m      8\u001b[0m     hid_rec\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/nirtorch/nirtorch/from_nir.py:145\u001b[0m, in \u001b[0;36mGraphExecutor.forward\u001b[0;34m(self, data, old_state)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39melem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m out, new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mold_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst_node\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m new_state\u001b[38;5;241m.\u001b[39mcache[node\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    153\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/nirtorch/nirtorch/from_nir.py:118\u001b[0m, in \u001b[0;36mGraphExecutor._apply_module\u001b[0;34m(self, node, input_nodes, new_state, old_state, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(summed_inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     inputs\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mstack(summed_inputs)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 118\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# If the module is stateful, we know the output is (at least) a tuple\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# HACK to make it work for snnTorch\u001b[39;00m\n\u001b[1;32m    121\u001b[0m is_rsynaptic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnntorch._neurons.rsynaptic.RSynaptic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    122\u001b[0m     node\u001b[38;5;241m.\u001b[39melem\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    123\u001b[0m )\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nir/snntorch/snntorch/_neurons/rsynaptic.py:314\u001b[0m, in \u001b[0;36mRSynaptic.forward\u001b[0;34m(self, input_, spk, syn, mem)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(spk, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(syn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(mem, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m ):  \u001b[38;5;66;03m# only triggered on first-pass\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     spk, syn, mem \u001b[38;5;241m=\u001b[39m _SpikeTorchConv(spk, syn, mem, input_\u001b[38;5;241m=\u001b[39minput_)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m ):  \u001b[38;5;66;03m# init_hidden case\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem \u001b[38;5;241m=\u001b[39m _SpikeTorchConv(\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem, input_\u001b[38;5;241m=\u001b[39minput_\n\u001b[1;32m    318\u001b[0m     )\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden:\n",
      "File \u001b[0;32m~/work/nir/nir/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RSynaptic' object has no attribute 'mem'"
     ]
    }
   ],
   "source": [
    "def apply(net, data):\n",
    "    state = None\n",
    "    hid_rec = []\n",
    "    out = []\n",
    "    for i, t in enumerate(data):\n",
    "        z, state = net(t, state)\n",
    "        out.append(z)\n",
    "        hid_rec.append(state)\n",
    "    spk_out = torch.stack(out)\n",
    "    # hid_rec = torch.stack(hid_rec)\n",
    "    return spk_out, hid_rec\n",
    "plt.imshow(apply(net, ds_test[0][0])[0].detach().T, aspect=5, interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251db4e6-841a-4878-8135-840628b058ce",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0652cd-4f57-4988-a626-88a340a4a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test_loop(dataset, batch_size, net, loss_fn, device, shuffle=True, saved_state_dict=None, label_probabilities=False, regularization=None):\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    if saved_state_dict != None:\n",
    "        net.load_state_dict(saved_state_dict)\n",
    "    net.eval()\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "\n",
    "    for data, labels in loader:\n",
    "        data = data.to(device).swapaxes(1, 0)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        spk_out, hid_rec = apply(net, data)\n",
    "\n",
    "        # Validation loss\n",
    "        if regularization != None:\n",
    "            # L1 loss on spikes per neuron from the hidden layer\n",
    "            reg_loss = regularization[0]*torch.mean(torch.sum(hid_rec, 0))\n",
    "            # L2 loss on total number of spikes from the hidden layer\n",
    "            reg_loss = reg_loss + regularization[1]*torch.mean(torch.sum(torch.sum(hid_rec, dim=0), dim=1)**2)\n",
    "            loss_val = loss_fn(spk_out, labels) + reg_loss\n",
    "        else:\n",
    "            loss_val = loss_fn(spk_out.sum(0), labels)\n",
    "\n",
    "        batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "        # Accuracy\n",
    "        act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
    "        _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "        batch_acc.extend((neuron_max_act_total_out == labels).detach().cpu().numpy()) # batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "    \n",
    "    if label_probabilities:\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
    "        log_p_y = log_softmax_fn(act_total_out)\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
    "    else:\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d083db-7860-4332-ad11-cf9276406226",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INFERENCE ON TEST SET\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "input_size = 12 \n",
    "num_steps = next(iter(ds_test))[0].shape[0]\n",
    "regularization = [parameters[\"reg_l1\"], parameters[\"reg_l2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9b252a-05e6-4943-8f79-fe2059281871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_val(graph):\n",
    "    net = #norse.torch.from_nir(graph, reset_method=reset_method)\n",
    "    return val_test_loop(ds_test, batch_size, net, loss_fn, device, shuffle=False)#, regularization=regularization)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4c4fb1-a425-4164-b86f-6d47bb343a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 18.57%\n"
     ]
    }
   ],
   "source": [
    "test_results = load_and_val(\"braille_subtract.nir\")\n",
    "np.save(\"snntorch_accuracy_subtract.npy\", np.round(test_results[1]*100,2))\n",
    "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262a74e4-f972-4516-a5ad-8680b77d09e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 12.86%\n"
     ]
    }
   ],
   "source": [
    "test_results = load_and_val(\"braille_retrained_zero.nir\", reset_method=norse.torch.functional.reset_value)\n",
    "np.save(\"snntorch_accuracy_zero.npy\", np.round(test_results[1]*100,2))\n",
    "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
