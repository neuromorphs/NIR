{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-3.5701e-01, -5.6863e-01, -1.1815e+00,  ..., -8.3889e-01,\n",
       "                       -1.9059e-01, -3.2760e-01],\n",
       "                      [-7.0992e-01, -8.6060e-01, -6.3683e-01,  ..., -1.2058e+00,\n",
       "                       -2.3467e-01, -5.9531e-01],\n",
       "                      [-3.0828e+00, -2.8350e+00, -3.4598e+00,  ..., -2.9395e+00,\n",
       "                       -2.3283e+00, -2.1144e+00],\n",
       "                      ...,\n",
       "                      [-6.2610e-01, -1.1959e+00, -8.1784e-01,  ..., -7.1882e-01,\n",
       "                       -6.2435e-01, -1.0815e+00],\n",
       "                      [ 3.3846e-02,  3.9589e-03, -2.2722e-01,  ..., -1.5527e-01,\n",
       "                       -3.9545e+00, -5.4881e+00],\n",
       "                      [-1.4432e+00, -1.7614e+00, -1.9475e+00,  ..., -1.4423e+00,\n",
       "                       -1.9547e+00, -1.1560e+00]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-9.8048e-01, -1.0654e+00, -3.8092e+00, -5.5239e-01, -3.1662e-01,\n",
       "                      -2.1900e+00, -7.3272e-01, -4.9665e-01, -1.0046e+00, -8.5759e-01,\n",
       "                      -1.4969e+00, -2.0559e+00, -6.6924e-02, -2.5154e+00, -5.0513e-02,\n",
       "                      -1.6159e-01, -5.5000e-01, -2.4662e+00,  1.4449e-01, -2.9386e+00,\n",
       "                      -1.2943e+00, -1.3403e-02, -8.1534e-01, -4.0596e-01, -2.2504e+00,\n",
       "                      -1.0796e+00, -1.4183e+00, -5.2309e-01,  1.1024e-01, -5.9571e-01,\n",
       "                      -3.6048e+00,  8.0316e-02, -9.0308e-01, -1.3158e+00, -7.1247e-01,\n",
       "                      -9.3804e-01, -3.6173e-01, -2.7558e-01, -1.2222e+00, -1.4776e+00,\n",
       "                      -1.9339e+00, -6.7409e-01, -5.8788e-01, -6.4386e-01, -3.2227e+00,\n",
       "                      -1.0718e+00, -2.7213e+00, -2.4823e+00, -3.8539e-01, -3.5545e+00,\n",
       "                      -1.6198e+00, -8.2098e-01, -5.1560e-01, -1.3715e+00, -1.8790e+00,\n",
       "                      -3.0497e+00, -1.9459e+00, -1.8636e+00, -2.4155e+00, -1.7588e+00,\n",
       "                      -8.8882e-01, -5.8311e-01, -1.5576e+00, -2.9450e+00, -8.3309e-01,\n",
       "                      -3.7968e-01, -1.0940e+00, -1.4301e+00, -2.7496e+00, -8.4589e-01,\n",
       "                      -2.6449e+00, -1.9737e-01, -7.1652e-01,  8.8886e-02, -1.9797e-01,\n",
       "                      -7.1980e-01, -1.5841e+00, -9.4706e-01, -1.0948e-02,  7.2104e-02,\n",
       "                      -2.0537e+00, -1.8541e+00, -1.5195e+00, -4.9637e-01, -1.9588e+00,\n",
       "                      -1.8414e+00, -6.8851e-01, -4.5262e-02, -2.1730e+00,  8.5641e-02,\n",
       "                       2.1145e-01, -1.1755e+00, -9.6658e-01, -5.1817e-01, -1.5857e+00,\n",
       "                      -1.3344e+00, -3.1829e+00,  7.1369e-02, -2.5872e-01, -5.6295e-01,\n",
       "                      -2.6769e+00, -1.4491e+00, -7.9346e-01, -2.0326e-01, -2.7744e-01,\n",
       "                      -1.9510e+00, -1.0948e+00,  2.0848e-01, -1.3318e+00, -4.7531e-01,\n",
       "                      -8.7486e-01, -1.2429e+00, -1.6093e+00, -3.9560e-01, -1.2217e+00,\n",
       "                      -1.5068e+00, -1.9365e-01, -9.6980e-01, -1.8479e+00, -1.1637e+00,\n",
       "                      -4.7621e-01, -2.0287e+00, -3.1231e+00, -2.2305e+00, -2.2180e+00,\n",
       "                      -1.7640e+00, -8.1686e-01, -3.1314e+00, -2.5227e+00, -1.5837e+00,\n",
       "                      -6.5151e-01, -3.0896e+00, -5.5269e-01, -9.0520e-01,  2.2084e-02,\n",
       "                      -3.3871e-02, -1.2270e+00, -1.2916e-01,  3.6822e-02, -1.0864e+00,\n",
       "                      -5.0043e-01, -6.0004e-01,  1.7150e-01, -1.0170e+00, -3.7540e+00,\n",
       "                      -3.0391e+00, -3.0894e+00, -2.4591e+00, -7.1905e-01, -7.0440e-01,\n",
       "                       9.0653e-02, -1.9467e+00, -1.4191e+00, -6.3307e-01, -2.8765e+00,\n",
       "                      -7.8565e-01, -1.6740e+00, -2.3837e+00, -3.0769e+00, -3.0286e+00,\n",
       "                      -1.2033e+00, -5.9763e-01, -2.3377e-01, -2.2514e+00, -2.0316e+00,\n",
       "                      -1.4588e+00, -2.2394e+00, -2.9045e+00, -3.2899e+00, -8.8628e-01,\n",
       "                      -3.2648e+00, -1.0203e+00, -7.3044e-01, -8.9795e-01, -2.0908e+00,\n",
       "                      -1.2679e+00, -1.3509e+00, -1.7372e+00, -1.2863e+00,  1.2005e-01,\n",
       "                      -2.2525e+00, -9.0789e-02, -2.5647e-01, -2.2575e+00, -1.3175e+00,\n",
       "                      -3.1464e+00, -1.9318e+00, -1.9416e+00, -3.4305e+00, -3.1441e+00,\n",
       "                      -2.8513e+00, -2.9637e+00, -9.7601e-01, -2.2610e+00, -1.0018e-01,\n",
       "                      -1.8348e+00, -2.6753e+00, -2.7575e-01, -6.2615e-01, -1.3770e+00,\n",
       "                      -8.4867e-01, -1.0427e+00, -3.5637e-01, -7.6187e-01, -1.2178e+00,\n",
       "                      -1.8656e+00, -6.0667e-01, -2.7055e+00, -1.1790e+00, -2.3924e+00,\n",
       "                      -1.9697e+00, -2.1633e+00, -8.3064e-01, -5.3765e-02, -7.8291e-01,\n",
       "                      -2.7900e+00, -3.6204e+00, -1.8417e-01, -2.9498e+00, -8.6315e-01,\n",
       "                      -2.9683e+00, -1.4424e+00, -1.7617e+00, -1.2206e+00, -6.6138e-01,\n",
       "                       1.1439e-01, -4.8186e-01, -6.7997e-01, -7.4331e-01, -1.9535e+00,\n",
       "                      -1.3811e+00, -3.8556e-01,  1.1599e-01, -1.5216e+00, -1.7952e+00,\n",
       "                       8.4104e-04, -3.9267e+00, -2.7102e-01, -3.4694e+00, -4.6832e-01,\n",
       "                       6.4139e-02, -2.4832e-01, -1.2462e+00, -7.9527e-01, -2.1888e-01,\n",
       "                      -5.7716e-03, -1.5067e+00, -1.1262e+00, -9.0508e-02, -3.0216e+00,\n",
       "                      -8.7465e-01, -1.2791e+00, -1.0060e+00, -4.1876e-02,  2.3008e-01,\n",
       "                      -8.6252e-01, -1.4297e+00, -2.2141e+00, -1.3619e+00, -1.2334e+00,\n",
       "                      -1.9114e-01, -1.7898e-02,  1.8301e-01, -5.8260e-01, -2.9537e+00,\n",
       "                       1.3637e-01, -9.2335e-01, -1.2997e+00, -2.0386e+00, -2.7021e+00,\n",
       "                      -1.3894e+00, -8.9075e-01, -2.9918e-01, -1.1958e+00, -2.1547e+00,\n",
       "                      -7.8592e-02, -2.6662e+00, -2.6820e+00, -8.0520e-01, -2.3169e+00,\n",
       "                       1.2807e-01, -1.0685e+00, -1.1064e+00, -1.9630e+00, -2.6818e+00,\n",
       "                      -2.2471e+00, -4.7979e-02, -1.2245e+00, -2.1653e+00, -3.2412e+00,\n",
       "                      -1.1319e-01, -1.3472e-01, -2.0960e+00, -1.6805e+00, -8.4553e-01,\n",
       "                      -1.1619e+00, -2.8104e+00, -3.7311e-01, -1.3078e-01,  1.5116e-01,\n",
       "                      -1.4139e+00, -1.5897e+00, -3.4046e+00, -2.6294e+00, -8.8029e-01,\n",
       "                      -2.2469e+00, -1.9665e+00, -2.4895e+00, -7.4176e-01, -1.0089e+00,\n",
       "                      -2.6433e-01, -7.2098e-01, -1.7325e+00, -7.1690e-01,  1.3770e-01,\n",
       "                      -8.7263e-01, -4.5519e-01, -1.7599e+00, -1.5376e-01, -1.1524e+00,\n",
       "                      -2.4295e-01,  1.9612e-01, -7.7221e-01, -6.3391e-01, -1.7987e+00,\n",
       "                      -6.8469e-01, -1.9987e+00, -9.6525e-01, -1.7261e+00,  6.5282e-02,\n",
       "                      -3.3913e+00, -2.1983e+00, -2.0360e+00, -2.3225e+00, -5.4678e-01,\n",
       "                      -7.5816e-01, -2.8604e+00, -1.2148e+00,  1.5795e-01, -2.5625e-01,\n",
       "                      -2.3847e+00, -1.3502e+00, -4.9769e-01, -7.1112e-01, -1.7059e+00,\n",
       "                      -2.7837e+00, -6.0850e-01, -1.4221e+00,  1.9983e-01, -1.7165e+00])),\n",
       "             ('lif1.threshold', tensor(1.)),\n",
       "             ('lif1.graded_spikes_factor', tensor(1.)),\n",
       "             ('lif1.reset_mechanism_val', tensor(1)),\n",
       "             ('lif1.beta', tensor(0.8500)),\n",
       "             ('lif1.recurrent.weight',\n",
       "              tensor([[ 8.9985e-03,  6.9575e-02, -5.1104e-03,  ..., -5.6053e-02,\n",
       "                       -2.3475e+00,  6.8110e-02],\n",
       "                      [-4.2454e-02,  5.2247e-02, -1.3950e-03,  ..., -3.5767e-02,\n",
       "                       -1.0459e+00,  1.1622e-02],\n",
       "                      [-3.1842e-02, -6.4594e-03, -3.0435e-02,  ..., -2.7094e-03,\n",
       "                       -5.6263e+00, -4.3682e-02],\n",
       "                      ...,\n",
       "                      [-4.4924e-02, -1.0366e-02,  5.0449e-03,  ..., -6.8217e-03,\n",
       "                       -1.7630e+00, -2.2116e-02],\n",
       "                      [-2.2972e-02,  1.3626e-02,  3.5905e-02,  ..., -3.3418e-02,\n",
       "                       -6.6782e-03,  9.7585e-03],\n",
       "                      [-5.2152e-02,  1.8054e-02, -3.4156e-02,  ..., -4.4623e-03,\n",
       "                       -1.2403e+00, -5.2070e-02]])),\n",
       "             ('lif1.recurrent.bias',\n",
       "              tensor([-1.0404, -1.0685, -3.6591, -0.7013, -0.3578, -2.0954, -0.8773, -0.6478,\n",
       "                      -1.1864, -0.8382, -1.2849, -2.1063, -0.0432, -2.4244, -0.2392, -0.0852,\n",
       "                      -0.7388, -2.2815,  0.0437, -2.7404, -1.2671, -0.1646, -0.9453, -0.2749,\n",
       "                      -2.2207, -1.2089, -1.3621, -0.6576,  0.0115, -0.6150, -3.5124,  0.1279,\n",
       "                      -0.9388, -1.2962, -0.6604, -1.0201, -0.2962, -0.0906, -1.2988, -1.3865,\n",
       "                      -1.7304, -0.8421, -0.7073, -0.6726, -3.1444, -1.1097, -2.5768, -2.6091,\n",
       "                      -0.3092, -3.3869, -1.7015, -0.9181, -0.6960, -1.4045, -1.8736, -2.9398,\n",
       "                      -1.7608, -1.9666, -2.4877, -1.5504, -1.0533, -0.4069, -1.5293, -2.8268,\n",
       "                      -0.9389, -0.2801, -1.0128, -1.3000, -2.5914, -0.8532, -2.5892, -0.0847,\n",
       "                      -0.8658, -0.0222, -0.2303, -0.8221, -1.3588, -0.9648, -0.0674,  0.0645,\n",
       "                      -1.9192, -1.6243, -1.6447, -0.6960, -1.8913, -1.8377, -0.8085,  0.0621,\n",
       "                      -2.0925, -0.0477, -0.0089, -1.1234, -0.9997, -0.7011, -1.5308, -1.1280,\n",
       "                      -3.0352,  0.1119, -0.4271, -0.7513, -2.5509, -1.3502, -0.7966, -0.2393,\n",
       "                      -0.1237, -1.9804, -1.0030,  0.0274, -1.2913, -0.3613, -0.9013, -1.0938,\n",
       "                      -1.4699, -0.1840, -1.2030, -1.4118, -0.2432, -1.0803, -1.7603, -1.1756,\n",
       "                      -0.2953, -1.8341, -3.0309, -2.0189, -2.0156, -1.8658, -0.9234, -3.0833,\n",
       "                      -2.3510, -1.4344, -0.8373, -3.0336, -0.6432, -0.9586,  0.0177, -0.1983,\n",
       "                      -1.2008, -0.1696,  0.0850, -1.1280, -0.4228, -0.7330,  0.0197, -1.0781,\n",
       "                      -3.5784, -2.8447, -3.0218, -2.4376, -0.9071, -0.5807,  0.0504, -1.9290,\n",
       "                      -1.2964, -0.8581, -2.8598, -0.8489, -1.5370, -2.3091, -2.9658, -2.8946,\n",
       "                      -1.1941, -0.5315, -0.1141, -2.2752, -1.8877, -1.5036, -2.1215, -2.8115,\n",
       "                      -3.0713, -1.0003, -3.2487, -1.1215, -0.7215, -0.9218, -2.0106, -1.2761,\n",
       "                      -1.4282, -1.6194, -1.1640,  0.0454, -2.2455, -0.2189, -0.3371, -2.0864,\n",
       "                      -1.2056, -3.0460, -1.8642, -1.8917, -3.2035, -3.0853, -2.7205, -2.7752,\n",
       "                      -0.9721, -2.4411, -0.3119, -1.7458, -2.5837, -0.0699, -0.5333, -1.3893,\n",
       "                      -0.9304, -1.2586, -0.1279, -0.9542, -1.0980, -1.7611, -0.7306, -2.8202,\n",
       "                      -1.1626, -2.1799, -1.9370, -2.1877, -0.9387, -0.2529, -0.9695, -2.6300,\n",
       "                      -3.4553, -0.3260, -2.7712, -1.0238, -2.8319, -1.4917, -1.8027, -1.1090,\n",
       "                      -0.7836,  0.1125, -0.6362, -0.8471, -0.8530, -1.8668, -1.2958, -0.5530,\n",
       "                       0.1133, -1.4283, -1.7090, -0.1469, -3.7929, -0.4048, -3.3036, -0.5560,\n",
       "                      -0.0879, -0.2836, -1.1231, -0.9220, -0.2709, -0.1113, -1.6069, -1.2076,\n",
       "                      -0.2108, -2.9497, -0.9450, -1.0929, -1.1013, -0.0635, -0.0220, -0.9988,\n",
       "                      -1.3600, -1.9849, -1.3601, -1.2413, -0.2302, -0.1481,  0.0041, -0.7438,\n",
       "                      -2.8753,  0.0858, -0.9574, -1.3582, -2.0249, -2.5152, -1.2299, -1.0495,\n",
       "                      -0.2392, -1.2232, -2.1675, -0.0477, -2.6440, -2.5571, -0.8464, -2.2634,\n",
       "                       0.0665, -1.0348, -1.1411, -2.0257, -2.5501, -2.0191, -0.2095, -1.0625,\n",
       "                      -1.9925, -3.0952, -0.1289, -0.2226, -2.0946, -1.5887, -0.8882, -1.2664,\n",
       "                      -2.7447, -0.4144, -0.2984, -0.0154, -1.4512, -1.4485, -3.2095, -2.4816,\n",
       "                      -1.0879, -2.2290, -1.8787, -2.3795, -0.7201, -1.1564, -0.4081, -0.8536,\n",
       "                      -1.8699, -0.8465, -0.0362, -1.0450, -0.3133, -1.5861, -0.1159, -1.2389,\n",
       "                      -0.3586,  0.0504, -0.8417, -0.7689, -1.8726, -0.7615, -1.8777, -0.9365,\n",
       "                      -1.8154,  0.1090, -3.2536, -2.1139, -1.8129, -2.1935, -0.7507, -0.5783,\n",
       "                      -2.9076, -1.2730,  0.0471, -0.3409, -2.2183, -1.3366, -0.7060, -0.7817,\n",
       "                      -1.7529, -2.7531, -0.6697, -1.1953,  0.0182, -1.7636])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0141,  0.0483, -0.0076,  ...,  0.0649, -1.2433,  0.0431],\n",
       "                      [-0.0036,  0.0215,  0.0327,  ..., -0.0087, -0.3731,  0.0386],\n",
       "                      [-0.0122,  0.0598, -0.0064,  ...,  0.0692, -0.9283,  0.0433],\n",
       "                      ...,\n",
       "                      [ 0.0129, -0.0144,  0.0127,  ...,  0.0123, -2.0207,  0.0788],\n",
       "                      [ 0.0352, -0.0243, -0.0296,  ...,  0.0329, -1.7190,  0.0625],\n",
       "                      [ 0.1048,  0.0644, -0.0088,  ...,  0.0358, -1.7383, -0.0106]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([0.4423, 0.3273, 0.2771, 0.3700, 0.2917, 0.3119, 0.2374, 0.2651, 0.2869,\n",
       "                      0.2822, 0.2727, 0.3692, 0.3160, 0.3396, 0.2484, 0.3259, 0.2395, 0.1946,\n",
       "                      0.2793, 0.2727, 0.2460, 0.3784, 0.3063, 0.2921, 0.3523, 0.2669, 0.2750])),\n",
       "             ('lif2.threshold', tensor(1.)),\n",
       "             ('lif2.graded_spikes_factor', tensor(1.)),\n",
       "             ('lif2.reset_mechanism_val', tensor(1)),\n",
       "             ('lif2.beta', tensor(0.9500))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.load(\"model_ref_20230827_182756.pt\", map_location=\"cpu\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fc1.weight',\n",
       " 'fc1.bias',\n",
       " 'lif1.threshold',\n",
       " 'lif1.graded_spikes_factor',\n",
       " 'lif1.reset_mechanism_val',\n",
       " 'lif1.beta',\n",
       " 'lif1.recurrent.weight',\n",
       " 'lif1.recurrent.bias',\n",
       " 'fc2.weight',\n",
       " 'fc2.bias',\n",
       " 'lif2.threshold',\n",
       " 'lif2.graded_spikes_factor',\n",
       " 'lif2.reset_mechanism_val',\n",
       " 'lif2.beta']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in m.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[\"lif1.graded_spikes_factor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = lambda *x: torch.randn(*x).numpy()\n",
    "n1 = 16\n",
    "n2 = 63\n",
    "g = nir.NIRGraph(\n",
    "    nodes = {\n",
    "        \"fc1\": nir.Affine(weight=gen(n1, 24), bias=gen(n1)),\n",
    "        \"lif1\": nir.CubaLIF(w_in=torch.eye(n1).numpy(),\n",
    "                            tau_mem=torch.full((n1,), 1).numpy(),\n",
    "                            tau_syn=torch.full((n1,), 1).numpy(),\n",
    "                            r=torch.full((n1,), 1).numpy(),\n",
    "                            v_leak=torch.zeros((n1,)).numpy(),\n",
    "                            v_threshold=torch.full((n1,), 1).numpy()),\n",
    "        \"lif1r\": nir.Affine(weight=gen(n2, n1), bias=gen(n2)),\n",
    "        \"fc2\": nir.Affine(weight=gen(n2, n2), bias=gen(n2)),\n",
    "        \"lif2\": nir.CubaLIF(w_in=torch.eye(n2).numpy(),\n",
    "                            tau_mem=torch.full((n2,), 1).numpy(),\n",
    "                            tau_syn=torch.full((n2,), 1).numpy(),\n",
    "                            r=torch.full((n2,), 1).numpy(),\n",
    "                            v_leak=torch.zeros((n2,)).numpy(),\n",
    "                            v_threshold=torch.ones((n2,)).numpy()),\n",
    "    },\n",
    "    edges = [(\"fc1\", \"lif1\"), (\"lif1\", \"lif1r\"), (\"lif1r\", \"lif1\"), (\"lif1\", \"fc2\"), (\"fc2\", \"lif2\")]\n",
    ")\n",
    "\n",
    "nir.write(\"braille.nir\", g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NIRGraph(nodes={'fc1': Affine(weight=array([[ 0.19632688, -0.15066636,  0.79383886, -0.6918571 , -1.1997273 ,\n",
       "         0.03167971,  0.09418193,  1.2134423 ,  1.015343  , -0.00683297,\n",
       "        -0.24639373,  0.23417024,  1.6612574 ,  1.4080112 , -0.72425294,\n",
       "         0.83691615,  0.52794087,  2.000234  , -0.18228869,  0.911659  ,\n",
       "         1.1834587 , -0.07246201,  0.29142314, -0.12610467],\n",
       "       [ 0.1005088 ,  0.25827315, -0.71275324,  1.2558497 , -0.08012172,\n",
       "        -0.17658281,  0.7774217 , -0.59269005,  0.84339434,  0.4337682 ,\n",
       "         0.05873786,  0.23892304,  0.06781289, -1.0675094 , -0.5197273 ,\n",
       "        -0.8751303 ,  0.7234639 , -0.6403121 , -0.7771464 ,  0.3853149 ,\n",
       "         1.2668241 , -1.234899  ,  0.55707663,  1.9268793 ],\n",
       "       [ 1.1873337 , -0.78655595, -0.5718737 ,  0.03339281,  0.16578901,\n",
       "         1.0672818 ,  0.5902614 , -0.68486565, -0.7119151 ,  1.0009782 ,\n",
       "        -0.821502  ,  0.12713674, -1.7987015 , -1.304858  , -0.6131657 ,\n",
       "         0.2677764 , -1.0950854 , -0.3037562 , -1.2107897 ,  0.76184577,\n",
       "        -0.23640507,  0.29597843,  1.2089186 ,  0.21639702],\n",
       "       [-1.940066  ,  1.4767352 , -0.8990447 ,  0.78971577, -0.378736  ,\n",
       "         0.26250032,  1.0210197 ,  0.4558777 ,  1.1629885 ,  0.7431412 ,\n",
       "        -0.02180973, -2.553206  , -0.51475793,  0.44980147, -0.8569791 ,\n",
       "         1.7384874 ,  1.0506034 , -0.20036827, -0.4474288 , -0.725753  ,\n",
       "         0.14697577,  0.73496825, -0.43606734, -0.15174176],\n",
       "       [-1.1904356 , -0.06872152,  0.29638788,  2.3409333 , -0.69248855,\n",
       "         1.4657477 , -0.4735399 ,  0.7927014 , -1.2063364 ,  1.9280267 ,\n",
       "         0.14504299, -0.51429   , -0.44315115,  0.82110935,  0.53574675,\n",
       "         0.5778887 ,  1.2249116 , -0.7396882 ,  0.07949165, -0.16955785,\n",
       "         0.48411703, -0.6581223 , -0.47528544, -0.17580774],\n",
       "       [ 0.16728202,  0.7630926 , -0.02524798,  1.0340884 ,  0.13144654,\n",
       "         0.5800146 ,  1.9910834 ,  1.0710691 , -0.07308286,  0.12998548,\n",
       "         0.1517524 ,  1.4807469 ,  0.79436606,  1.7160909 ,  1.747043  ,\n",
       "        -1.1308875 ,  2.385807  ,  1.4609461 , -0.66817987,  1.1111358 ,\n",
       "         0.13417538,  0.2968386 ,  0.02396123, -0.10520243],\n",
       "       [-0.26306218, -1.7765081 ,  1.4331069 ,  1.056885  ,  1.9828151 ,\n",
       "         1.5369239 ,  1.4551197 , -0.69392866, -0.5767468 ,  2.0401049 ,\n",
       "        -0.01314999,  1.3558469 ,  2.2621727 ,  1.9593784 , -0.2988161 ,\n",
       "         1.3274333 , -0.2314212 , -0.921873  , -0.3425068 ,  1.0046818 ,\n",
       "         0.7025336 ,  1.092225  ,  0.54669976, -0.09700903],\n",
       "       [ 1.8624463 ,  0.7005127 ,  0.6235941 , -0.13428813,  0.3789186 ,\n",
       "        -0.67950207, -0.36109614,  0.19793472,  0.22637998, -0.6461992 ,\n",
       "        -1.2390821 ,  1.3341137 , -0.49708647, -1.6299148 ,  0.9327192 ,\n",
       "         0.2972809 ,  1.2688892 , -0.19988461, -1.7509775 ,  0.07392807,\n",
       "         0.6359472 , -0.81407464,  0.4074286 , -0.6944763 ],\n",
       "       [ 0.10903218, -1.1356215 ,  1.6504334 , -1.1652046 , -1.257832  ,\n",
       "        -0.40358105, -1.08241   ,  0.8482327 ,  1.3060751 ,  0.41470584,\n",
       "         0.17423171, -1.7182053 , -0.09520884, -1.0903834 ,  0.7970719 ,\n",
       "        -0.49630857,  0.10569163,  1.4992626 , -2.6071386 , -1.1556871 ,\n",
       "         1.2527343 ,  0.445406  ,  0.5199523 ,  0.7397535 ],\n",
       "       [ 1.46369   ,  0.21868894, -1.1543797 ,  1.9605591 , -0.6512661 ,\n",
       "        -0.7989319 , -0.51138103,  1.312664  ,  2.0670638 , -0.11329984,\n",
       "         0.49795714, -0.3901659 ,  0.8879315 ,  0.2034443 ,  1.494596  ,\n",
       "         1.794303  ,  1.275507  ,  0.72061294, -0.21800542,  0.41264838,\n",
       "        -0.02074804, -0.3094926 ,  1.758372  , -1.2873236 ],\n",
       "       [ 0.8380296 ,  0.8076149 ,  1.5317969 ,  0.14184156, -1.0956163 ,\n",
       "        -1.4194478 , -1.0088536 , -1.4300033 , -1.2154233 ,  1.5772444 ,\n",
       "         2.1239946 ,  0.95652676, -0.58160186,  0.18278986, -2.4974887 ,\n",
       "         0.6157253 ,  1.0659788 ,  1.1180574 , -0.34170473, -0.03604959,\n",
       "         1.1842867 ,  2.9163632 , -1.2563552 , -1.5232792 ],\n",
       "       [ 1.3996202 ,  0.34534466, -0.25840026, -0.28775713, -0.01141354,\n",
       "        -0.68516314, -0.730365  ,  1.5885426 ,  2.0862594 ,  1.4363909 ,\n",
       "        -0.42864954,  0.5268292 , -0.41359383, -2.4898286 , -0.9777616 ,\n",
       "        -0.2573511 ,  0.7153899 ,  0.09063461,  2.4716635 ,  0.20728298,\n",
       "         0.80483097, -2.9800737 ,  1.7054855 , -1.1817567 ],\n",
       "       [-1.8358558 ,  0.28442046,  2.0086782 ,  0.27865133, -1.7967433 ,\n",
       "         0.60628283, -0.2229027 , -0.74432886, -1.6157142 ,  0.1378639 ,\n",
       "         1.2628564 ,  1.2610608 ,  0.09228601, -0.17325772,  1.2532989 ,\n",
       "        -0.21308717, -0.40753073, -0.6177335 , -1.3408138 ,  2.0679672 ,\n",
       "         1.6830554 , -0.73608893,  0.3060775 ,  0.5008901 ],\n",
       "       [-1.3976035 ,  0.69420654, -1.4415637 ,  0.06988362, -0.02532908,\n",
       "        -0.45688954, -2.7575366 , -0.56570715,  1.2712774 ,  0.83834213,\n",
       "        -1.9372199 ,  1.2037584 ,  1.8207853 , -0.7400128 , -0.3548238 ,\n",
       "        -0.6176836 , -0.02803708,  1.2053064 ,  0.02561798,  0.79100716,\n",
       "         2.5293798 , -0.64025277, -0.3690912 , -0.62969315],\n",
       "       [-0.5277784 , -0.59023327,  0.8789925 ,  0.6307633 , -0.48009786,\n",
       "        -2.077924  , -0.18536338,  0.72277355, -0.00558406,  0.03566027,\n",
       "         1.6618212 , -0.439151  , -0.39539793,  0.21209899,  1.2199043 ,\n",
       "        -1.1590524 ,  0.9642458 , -1.142965  , -2.1372452 , -1.7806463 ,\n",
       "         0.6049384 , -0.09878053, -1.8551984 ,  0.77393264],\n",
       "       [-0.80815256,  0.2156983 , -0.5498925 , -1.5933276 ,  0.26385504,\n",
       "        -1.1790943 , -0.4221098 , -1.642768  , -1.3361603 ,  0.4162342 ,\n",
       "         0.49745706, -1.1907808 , -0.43458953, -0.36553282,  1.7875103 ,\n",
       "         0.03571441,  2.4014251 ,  1.3510419 ,  0.71758026,  0.54125684,\n",
       "        -0.03736119,  0.35435796, -0.08721148, -0.10697075]],\n",
       "      dtype=float32), bias=array([ 2.0968568 ,  1.2855929 , -0.37407774,  2.0494087 ,  0.4553388 ,\n",
       "        0.5022041 , -0.30041462, -1.3332689 ,  0.29939613, -0.17170559,\n",
       "       -0.791684  , -0.10862304, -0.85140055,  0.8518336 ,  0.02784523,\n",
       "        0.7138877 ], dtype=float32)), 'fc2': Affine(weight=array([[-0.47018757, -1.0758188 ,  1.4164928 , ...,  0.4620965 ,\n",
       "         0.550316  ,  0.347345  ],\n",
       "       [-0.03297261,  0.8840759 ,  2.17184   , ...,  1.1928422 ,\n",
       "         0.419662  , -0.23023076],\n",
       "       [ 1.3204473 , -0.0382672 ,  0.22190589, ...,  0.586383  ,\n",
       "        -1.6449645 , -0.16568384],\n",
       "       ...,\n",
       "       [-0.5180836 ,  0.34948558,  0.22335604, ..., -0.8794786 ,\n",
       "        -1.476343  ,  0.3087852 ],\n",
       "       [ 0.6308723 , -0.9663164 ,  0.1681139 , ...,  1.3116032 ,\n",
       "        -0.42940322, -1.7434535 ],\n",
       "       [ 0.4585862 ,  0.01196525, -0.3061487 , ...,  0.9315666 ,\n",
       "        -1.9693071 ,  0.04157504]], dtype=float32), bias=array([ 0.2710428 ,  1.1027653 , -0.74103516,  0.45452872, -1.3836365 ,\n",
       "        1.8846508 , -0.99908185, -1.4048456 , -0.54273856, -2.0641634 ,\n",
       "        0.269608  , -0.89258736, -1.4036293 ,  0.26795885, -1.1554433 ,\n",
       "       -0.9386463 ,  0.64575064, -0.5764551 , -0.30400875,  0.27678275,\n",
       "        0.38490522,  0.09313551, -0.3304793 ,  0.47773147, -2.1791682 ,\n",
       "       -0.83495164,  0.56854826,  0.5207914 , -1.3865142 , -0.31548077,\n",
       "        1.2533602 ,  0.43439323,  0.02234822, -0.44506872,  1.1240814 ,\n",
       "        1.5934882 ,  0.51019955,  1.6220493 ,  0.75827795, -0.5715163 ,\n",
       "       -0.34961167, -1.1621101 , -0.2453749 ,  2.1588268 , -0.38349077,\n",
       "       -1.3300489 ,  1.8325722 ,  1.4840003 , -0.7914404 ,  0.62627596,\n",
       "       -0.77081114, -1.1483616 , -1.0426869 , -0.19525634, -0.03401212,\n",
       "       -2.5228202 , -0.04922728, -1.3305149 ,  0.39362273,  0.5517294 ,\n",
       "       -0.744737  , -0.77270734, -0.18490872], dtype=float32)), 'lif1': CubaLIF(tau_syn=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tau_mem=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), r=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), v_leak=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), v_threshold=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), w_in=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 'lif1r': Affine(weight=array([[ 2.2607586 ,  0.03580342,  1.2687021 , ..., -1.2457329 ,\n",
       "        -0.5668815 ,  1.9329828 ],\n",
       "       [ 1.2287655 ,  1.0210236 ,  0.09847476, ..., -0.63059187,\n",
       "        -0.4832524 ,  0.07938681],\n",
       "       [-0.62594265,  0.9511714 ,  1.0176668 , ...,  0.7906057 ,\n",
       "        -0.11435723, -0.08643844],\n",
       "       ...,\n",
       "       [ 0.98436296,  1.1838579 ,  0.5230855 , ..., -0.37907702,\n",
       "         1.1735574 ,  0.6077542 ],\n",
       "       [-1.6934545 , -1.9666845 ,  0.9291854 , ..., -1.576989  ,\n",
       "        -1.378316  ,  1.429115  ],\n",
       "       [-0.01341278, -0.88381636,  0.2049001 , ..., -1.7201502 ,\n",
       "         0.07789452, -0.87243897]], dtype=float32), bias=array([-0.6557057 , -0.43089566, -0.89832383, -1.3832793 ,  0.49775642,\n",
       "       -1.6132226 ,  0.22804657,  0.20529965, -0.03653516,  0.63481414,\n",
       "       -1.1197001 ,  1.1271017 , -0.09611461,  2.31652   , -1.1215153 ,\n",
       "        0.6909196 ,  0.6697126 , -0.9779857 ,  1.3039285 , -0.16962993,\n",
       "       -1.5951583 ,  0.1165119 ,  1.1931891 ,  1.4854827 ,  0.17883842,\n",
       "        1.0554348 ,  0.48216984, -0.95055723,  0.01901425,  1.2789534 ,\n",
       "        1.2014973 ,  0.48876163, -0.9402812 , -0.81377876,  1.07314   ,\n",
       "       -1.2070516 ,  0.72873974, -0.16973461,  0.2222285 ,  0.9295702 ,\n",
       "        0.4838712 , -0.8577192 ,  0.9808529 ,  0.5416225 , -0.7161684 ,\n",
       "        0.68263185,  1.91193   ,  0.7365287 ,  0.15763085,  0.07518306,\n",
       "        0.41643634,  0.09268385, -0.3686248 , -0.99922174,  0.5159662 ,\n",
       "        0.35497883, -0.05620804, -1.2868614 , -2.2308633 ,  0.77888304,\n",
       "        1.5196699 , -0.5275534 , -0.9265105 ], dtype=float32)), 'lif2': CubaLIF(tau_syn=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tau_mem=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), r=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), v_leak=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), v_threshold=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), w_in=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32))}, edges=[('fc1', 'lif1'), ('lif1', 'lif1r'), ('lif1r', 'lif1'), ('lif1', 'fc2'), ('fc2', 'lif2')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir.read(\"braille.nir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import norse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphExecutor(\n",
       "  (fc1): Linear(in_features=24, out_features=16, bias=True)\n",
       "  (lif1): LIFCell(p=LIFParameters(tau_syn_inv=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tau_mem_inv=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), v_leak=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), v_th=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), v_reset=tensor(0.), method='super', alpha=tensor(100.)), dt=0.001)\n",
       "  (lif1r): Linear(in_features=16, out_features=63, bias=True)\n",
       "  (fc2): Linear(in_features=63, out_features=63, bias=True)\n",
       "  (lif2): LIFCell(\n",
       "    p=LIFParameters(tau_syn_inv=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1.]), tau_mem_inv=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1.]), v_leak=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), v_th=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "            1., 1., 1., 1., 1., 1., 1., 1., 1.]), v_reset=tensor(0.), method='super', alpha=tensor(100.)), dt=0.001\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norse.torch.from_nir(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
