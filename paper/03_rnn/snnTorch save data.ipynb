{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a36e5c-e173-44f4-a26d-41146c88bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import snntorch\n",
    "import nirtorch\n",
    "from snntorch import import_nirtorch\n",
    "import matplotlib.pyplot as plt\n",
    "import nir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc6de51-8cd1-4781-bad8-6876e9352e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"data/ds_test.pt\"\n",
    "ds_test = torch.load(test_data_path)\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb02d6",
   "metadata": {},
   "source": [
    "## save activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5a4c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n",
      "HAS BIAS\n",
      "HAS BIAS\n",
      "HAS BIAS\n",
      "torch.Size([256, 12])\n",
      "torch.Size([256, 7])\n",
      "(256, 38)\n"
     ]
    }
   ],
   "source": [
    "nir_graph = nir.read(\"braille_noDelay_bias_zero.nir\")\n",
    "net = import_nirtorch.from_nir(nir_graph)\n",
    "h_state = nirtorch.from_nir.GraphExecutorState(\n",
    "    state={\n",
    "        'lif1': net._modules['lif1'].init_rsynaptic(),  # 3-tuple: spk, syn, mem\n",
    "        'lif2': net._modules['lif2'].init_synaptic(),  # 2-tuple: syn, mem\n",
    "    }\n",
    ")\n",
    "spk_out_arr = []\n",
    "h_state_arr = []\n",
    "data_snn = ds_test[0][0]\n",
    "print(data_snn.shape)\n",
    "for t in range(data_snn.shape[0]):\n",
    "    spk_out_snn, h_state = net(data_snn[t], h_state)\n",
    "    spk_out_arr.append(spk_out_snn)\n",
    "    h_state_arr.append(h_state)\n",
    "spk_out_arr = torch.stack(spk_out_arr, dim=0)\n",
    "print(spk_out_arr.shape)\n",
    "spk_lif1_arr = [h_state.cache['lif1'] for h_state in h_state_arr]\n",
    "spk_lif1_arr = torch.stack(spk_lif1_arr, dim=0).detach().numpy()\n",
    "print(spk_lif1_arr.shape)\n",
    "np.save('snntorch_activity_noDelay_bias_zero.npy', spk_lif1_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752d6aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n",
      "torch.Size([256, 12])\n",
      "torch.Size([256, 7])\n",
      "(256, 40)\n"
     ]
    }
   ],
   "source": [
    "nir_graph = nir.read(\"braille_noDelay_noBias_subtract.nir\")\n",
    "net = import_nirtorch.from_nir(nir_graph)\n",
    "h_state = nirtorch.from_nir.GraphExecutorState(\n",
    "    state={\n",
    "        'lif1': net._modules['lif1'].init_rsynaptic(),  # 3-tuple: spk, syn, mem\n",
    "        'lif2': net._modules['lif2'].init_synaptic(),  # 2-tuple: syn, mem\n",
    "    }\n",
    ")\n",
    "spk_out_arr = []\n",
    "h_state_arr = []\n",
    "data_snn = ds_test[0][0]\n",
    "print(data_snn.shape)\n",
    "for t in range(data_snn.shape[0]):\n",
    "    spk_out_snn, h_state = net(data_snn[t], h_state)\n",
    "    spk_out_arr.append(spk_out_snn)\n",
    "    h_state_arr.append(h_state)\n",
    "spk_out_arr = torch.stack(spk_out_arr, dim=0)\n",
    "print(spk_out_arr.shape)\n",
    "spk_lif1_arr = [h_state.cache['lif1'] for h_state in h_state_arr]\n",
    "spk_lif1_arr = torch.stack(spk_lif1_arr, dim=0).detach().numpy()\n",
    "print(spk_lif1_arr.shape)\n",
    "np.save('snntorch_activity_noDelay_noBias_subtract.npy', spk_lif1_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ec5e6",
   "metadata": {},
   "source": [
    "## save accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c90ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_accuracy(nir_graph_file, save_to_npy_file):\n",
    "    nir_graph = nir.read(nir_graph_file)\n",
    "    net = import_nirtorch.from_nir(nir_graph)\n",
    "\n",
    "    batch_size = 64\n",
    "    shuffle = False\n",
    "    loader = DataLoader(ds_test, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        batch_acc = []\n",
    "        for data, labels in loader:  # data comes as: NTC\n",
    "            data_snn = data.swapaxes(1, 0)  # TNC\n",
    "            h_state = nirtorch.from_nir.GraphExecutorState(\n",
    "                state={\n",
    "                    'lif1': net._modules['lif1'].init_rsynaptic(),  # 3-tuple: spk, syn, mem\n",
    "                    'lif2': net._modules['lif2'].init_synaptic(),  # 2-tuple: syn, mem\n",
    "                }\n",
    "            )\n",
    "            spk_out_arr = []\n",
    "            for t in range(data_snn.shape[0]):\n",
    "                spk_out_snn, h_state = net(data_snn[t], h_state)\n",
    "                spk_out_arr.append(spk_out_snn)\n",
    "            spk_out_arr = torch.stack(spk_out_arr, dim=0)\n",
    "            print(spk_out_arr.shape)\n",
    "\n",
    "            act_total_out = torch.sum(spk_out_arr, 0)  # sum over time\n",
    "            _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax output > labels\n",
    "            batch_acc.extend((neuron_max_act_total_out == labels).detach().cpu().numpy())\n",
    "\n",
    "    print(np.mean(batch_acc))\n",
    "    np.save(save_to_npy_file, np.mean(batch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c723981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n",
      "HAS BIAS\n",
      "HAS BIAS\n",
      "HAS BIAS\n",
      "torch.Size([256, 64, 7])\n",
      "torch.Size([256, 64, 7])\n",
      "torch.Size([256, 12, 7])\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "model = 'noDelay_bias_zero'\n",
    "save_accuracy(f\"braille_{model}.nir\", f\"snntorch_accuracy_{model}.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a472cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n",
      "torch.Size([256, 64, 7])\n",
      "torch.Size([256, 64, 7])\n",
      "torch.Size([256, 12, 7])\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "model = 'noDelay_noBias_subtract'\n",
    "save_accuracy(f\"braille_{model}.nir\", f\"snntorch_accuracy_{model}.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
