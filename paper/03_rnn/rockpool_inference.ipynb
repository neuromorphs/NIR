{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90ef879f-6a43-4e2d-88e8-9992e6ad0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nir\n",
    "import torch\n",
    "import numpy as np\n",
    "from rockpool.nn.modules.torch.nir import from_nir, to_nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45dc16cf-cb3b-4e0f-a96e-f70e133a3cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2310_model_rework.ipynb\t   lava_inference.ipynb\n",
      " analyze_graph.py\t\t   lava_rnn.py\n",
      " Braille_inference.bak.ipynb\t  'Norse inference.ipynb'\n",
      " Braille_inference.ipynb\t   README.md\n",
      " Braille_inference_spinnaker2.py   rockpool_inference.ipynb\n",
      " braille.nir\t\t\t   samna.log\n",
      " braille_subgraph.nir\t\t   snntorch_debug_nirgraphs.ipynb\n",
      " collapsed.zip\t\t\t   snntorch_debug.py\n",
      " data\t\t\t\t   snntorch_test_export.py\n",
      " flatten_braille_graph.py\t   snntorch_test_import.py\n",
      " generate_rnn_nir_graph.py\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db16c3c3-f479-4b60-a1ff-01e4aeae08b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('input', 'fc1'),\n",
       " ('lif1.w_rec', 'lif1.lif'),\n",
       " ('fc2', 'lif2'),\n",
       " ('lif1.lif', 'lif1.w_rec'),\n",
       " ('lif2', 'output'),\n",
       " ('fc1', 'lif1.lif'),\n",
       " ('lif1.lif', 'fc2')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir.read(\"braille.nir\").edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b04550c-6948-4007-b951-6ee6cf6992ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jens/work/rockpool/rockpool/nn/modules/torch/linear_torch.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight) if weight is not None else None,\n",
      "/home/jens/work/rockpool/rockpool/nn/modules/torch/torch_module.py:258: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  super().register_parameter(key, nn.Parameter(torch.tensor(value.data)))\n",
      "/home/jens/work/rockpool/rockpool/nn/modules/torch/nir.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dt=torch.min(torch.tensor(_to_tensor(node.tau_mem / (1+node.r)))).item(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphExecutor(\n",
       "  (fc1): LinearTorch()\n",
       "  (fc2): LinearTorch()\n",
       "  (input): Identity()\n",
       "  (lif1_lif): LIFTorch()\n",
       "  (lif1_w_rec): LinearTorch()\n",
       "  (lif2): LIFTorch()\n",
       "  (output): Identity()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nirgraph = nir.read('braille.nir')\n",
    "net = from_nir(nirgraph)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3983e407-7504-4fe6-bad9-31b3f62304ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST DATA\n",
    "test_data_path = \"data/ds_test.pt\"\n",
    "ds_test = torch.load(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3602911c-b94f-4be1-9dae-c98331a9e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "state = None\n",
    "for t in ds_test[0][0]:\n",
    "    z, state = net(t, state)\n",
    "    out.append(z)\n",
    "out = torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25009ecb-a3dc-4bc9-be9e-ad702e080a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 14.29%\n"
     ]
    }
   ],
   "source": [
    "import snntorch.functional as SF\n",
    "### LOSS FUNCTION\n",
    "loss_fn = SF.ce_count_loss()\n",
    "\n",
    "def val_test_loop(dataset, batch_size, net, loss_fn, device, shuffle=True, saved_state_dict=None, label_probabilities=False, regularization=None):\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    if saved_state_dict != None:\n",
    "        net.load_state_dict(saved_state_dict)\n",
    "    net.eval()\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "\n",
    "    for data, labels in loader:\n",
    "        data = data.to(device).swapaxes(1, 0)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        spk_out, hid_rec = net(data)\n",
    "\n",
    "        # Validation loss\n",
    "        if regularization != None:\n",
    "            # L1 loss on spikes per neuron from the hidden layer\n",
    "            reg_loss = regularization[0]*torch.mean(torch.sum(hid_rec, 0))\n",
    "            # L2 loss on total number of spikes from the hidden layer\n",
    "            reg_loss = reg_loss + regularization[1]*torch.mean(torch.sum(torch.sum(hid_rec, dim=0), dim=1)**2)\n",
    "            loss_val = loss_fn(spk_out, labels) + reg_loss\n",
    "        else:\n",
    "            loss_val = loss_fn(spk_out, labels)\n",
    "\n",
    "        batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "        # Accuracy\n",
    "        act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
    "        _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "        batch_acc.extend((neuron_max_act_total_out == labels).detach().cpu().numpy()) # batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "    \n",
    "    if label_probabilities:\n",
    "        log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
    "        log_p_y = log_softmax_fn(act_total_out)\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
    "    else:\n",
    "        return [np.mean(batch_loss), np.mean(batch_acc)]\n",
    "\n",
    "test_results = val_test_loop(ds_test, 16, net, loss_fn, \"cpu\")\n",
    "\n",
    "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4992f64-3845-46c3-bee5-2b000698cd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
