{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiking CNN from NIR to SpiNNaker2\n",
    "\n",
    "In this notebook we will show how a pre-trained Spiking CNN NIR model can be deployed onto the SpiNNaker2 chip.\n",
    "\n",
    "py-spinnaker2, the high-level software interface for running spiking neural networks on SpiNNaker2, provides an API similar to PyNN and allows to define populations (groups of neurons with the same neuron model) and projections (group of synapses between two populations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import norse\n",
    "import numpy as np\n",
    "import tonic\n",
    "import torch\n",
    "import tqdm\n",
    "from spinnaker2 import brian2_sim, hardware, s2_nir, snn\n",
    "\n",
    "import nir\n",
    "\n",
    "class Args(object):\n",
    "    pass\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select to run either on Brian2 or on SpiNNaker2.\n",
    "We can run the same network on the Brian2 simulator or on SpiNNaker2. Select one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.s2_ip = \"brian2\"        # use Brian2 Simulator\n",
    "#args.s2_ip = \"192.168.1.48\"  # enter the IP of the SpiNNaker2 board\n",
    "print(args.s2_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NIR model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cnn_sinabs.nir\"\n",
    "nir_graph = nir.read(model_path)\n",
    "\n",
    "# make sure all nodes have necessary shape information\n",
    "nir_graph.infer_types()\n",
    "s2_nir.model_summary(nir_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to record the output of intermediate IF neurons, use `s2_nir.add_output_to_node`. Only do this if you actually want to record because this will slow down the iterations significantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an output to neurons of layer '1'\n",
    "# s2_nir.add_output_to_node('1', nir_graph, '1_out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NIR graph into py-spinnaker2 network\n",
    "Converts the graph from NIR into a spinnaker2.snn.Network().\n",
    "The ConversionConfig object gives several options specific to the py-spinnaker2 interface.\n",
    "- The `output_record` configures what should be recorded at the network outputs: spikes `[\"spikes\"]`, membrane potantials `[\"v\"]` or both `[\"spikes\", \"v\"]`.\n",
    "- `dt`: integration time constant\n",
    "- `conn_delay`: the connections between neurons can have a delay of multiples of `dt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for converting NIR graph to SpiNNaker2\n",
    "conversion_cfg = s2_nir.ConversionConfig()\n",
    "conversion_cfg.output_record = [\"spikes\"]\n",
    "conversion_cfg.dt = 0.0001\n",
    "conversion_cfg.conn_delay = 0\n",
    "conversion_cfg.scale_weights = True # Scale weights to dynamic range on chip\n",
    "conversion_cfg.reset = s2_nir.ResetMethod.ZERO # Reset voltage to zero at spike\n",
    "conversion_cfg.integrator = s2_nir.IntegratorMethod.FORWARD # Euler-Forward\n",
    "\n",
    "net, inp, outp = s2_nir.from_nir(nir_graph, conversion_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize neurons per core\n",
    "Because of memory and compute time limitations per core, we need to reduce the number of neurons per core for some of the neuron populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_atoms_per_core = {\n",
    "    \"3\": 256,\n",
    "    \"6\": 128,\n",
    "    \"10\": 16\n",
    "}\n",
    "for pop in net.populations:\n",
    "    if pop.name in max_atoms_per_core.keys():\n",
    "        pop.set_max_atoms_per_core(max_atoms_per_core[pop.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on Neuromorphic MNIST\n",
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_frame = tonic.transforms.ToFrame(\n",
    "    sensor_size=tonic.datasets.NMNIST.sensor_size, time_window=1e3\n",
    ")\n",
    "dataset = tonic.datasets.NMNIST(\".\", transform=to_frame, train=False)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    collate_fn=tonic.collation.PadTensors(batch_first=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert input data to spikes\n",
    "While the torch dataset uses tensors, py-spinnaker2's input populations of type spike_list require spike times as input. Here's the conversion function that also considers flattening of the 3-dimensional frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(x):\n",
    "    print(x.shape)\n",
    "    d = {}\n",
    "    # T = x.shape[0]\n",
    "    C = x.shape[2]\n",
    "    H = x.shape[3]\n",
    "    W = x.shape[4]\n",
    "    for c in range(C):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                d[c * H * W + h * W + w] = x[:, 0, c, h, w].nonzero()[0].tolist()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of Hardware or Simulator Backend\n",
    "If we use Brian2, we can now create the Backend, for SpiNNaker2 we have to do this for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_brian2 = args.s2_ip is None or args.s2_ip==\"brian2\"\n",
    "if use_brian2:\n",
    "    # brian2 backend can be reused\n",
    "    hw = brian2_sim.Brian2Backend()\n",
    "    print(\"\\nUsing brian2 simulator!\")\n",
    "else:\n",
    "     # S2 Hardware has to be created for each sample processed -> in loop\n",
    "    print(f\"\\nUsing SpiNNaker2 at IP {args.s2_ip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of a single sample\n",
    "This is a function to evaluate one single sample of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(hw, net, inp, outp, x, y):\n",
    "    input_spikes = convert_input(x)\n",
    "    inp[0].params = input_spikes\n",
    "\n",
    "    timesteps = x.shape[0] + 1\n",
    "    net.reset()\n",
    "    hw.run(net, timesteps, sys_tick_in_s=2.5e-3, debug=False)\n",
    "\n",
    "    out_spikes = np.zeros(10)\n",
    "    out_spike_times = outp[0].get_spikes()\n",
    "    for idx, spikes in out_spike_times.items():\n",
    "        # we are interested in spike rate, not count or exact times\n",
    "        out_spikes[idx] = len(spikes) / x.shape[0]\n",
    "    return np.argmax(out_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the complete dataset on SpiNNaker2 or Simulator\n",
    "Iterates over the complete dataset and calles the evaluate() function from above. Warning: This will usually take several hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_spike = []\n",
    "groundtruth = []\n",
    "import sys\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(loader, file=sys.stdout):\n",
    "        x, y = batch\n",
    "        x = x.detach().numpy()\n",
    "        y = y.detach().numpy()\n",
    "        print(\" \")\n",
    "        # We have to create S2 Chip connection\n",
    "        if not use_brian2:\n",
    "            hw = hardware.SpiNNaker2Chip(eth_ip=args.s2_ip)  # use ethernet\n",
    "        pred_spike = evaluate(hw, net, inp, outp, x, y)\n",
    "\n",
    "        # If we are using SpiNNaker2 chip, we have to delete the connection after use\n",
    "        if not use_brian2:\n",
    "            del hw\n",
    "        predicted_spike.append(pred_spike)\n",
    "        groundtruth.append(y[0])\n",
    "        accuracy_spike = np.mean(np.array(predicted_spike) == np.array(groundtruth))\n",
    "        print(f\"Prediction:{pred_spike}, ground truth: {y[0]}\")\n",
    "        print(\n",
    "            f\"Current accuracy: {accuracy_spike:.4f}\"\n",
    "        )\n",
    "print(\"\\nFinished!\\n\")\n",
    "\n",
    "final_accuracy = np.mean(np.array(predicted_spike) == np.array(groundtruth))\n",
    "\n",
    "print(f\"\\nFinal accuracy: {final_accuracy:.4f}\")\n",
    "acc_file = \"s2_brian2_accuracy.npy\" if use_brian2 else \"s2_accuracy.npy\"\n",
    "np.save(acc_file, final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity\n",
    "Now we want to get the activity output of the first IF layer, using a smaller dataset. In order to be able to extract the activity, we need to add an output to the net first.\n",
    "\n",
    "We could use:\n",
    "```\n",
    "s2_nir.add_output_to_node('1', nir_graph, '1_out')\n",
    "```\n",
    "But then we would have to do a few of the other steps again. Instead, let us just modify the already converted net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = None\n",
    "for pop in net.populations:\n",
    "    if pop.name == \"1\":\n",
    "        pop.record = [\"spikes\"]\n",
    "        outp = [pop]\n",
    "        break\n",
    "print(\"outp\", outp[0].name, outp[0].record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"cnn_numbers.npy\")\n",
    "count = data.shape[1]\n",
    "timesteps = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(hw, net, inp, outp, x):\n",
    "    input_spikes = convert_input(x)\n",
    "    inp[0].params = input_spikes\n",
    "\n",
    "    timesteps = x.shape[0] + 1\n",
    "    net.reset()\n",
    "    hw.run(net, timesteps, sys_tick_in_s=2.5e-3, debug=False)\n",
    "\n",
    "    out_spike_times = outp[0].get_spikes()\n",
    "    out_spikes = np.zeros((301, len(out_spike_times)))\n",
    "    for idx, spikes in out_spike_times.items():\n",
    "        # we are interested in spike rate, not count or exact times\n",
    "        out_spikes[spikes, idx] = 1\n",
    "        \n",
    "    out_spikes = out_spikes.reshape((301,1,16,16,16))\n",
    "    return out_spikes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterate over new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spikes = np.zeros((301,10,16,16,16))\n",
    "for i in range(count):\n",
    "    x = data[:,i:i+1,...]\n",
    "    \n",
    "    if not use_brian2:\n",
    "        hw = hardware.SpiNNaker2Chip(eth_ip=args.s2_ip)  # use ethernet\n",
    "    \n",
    "    pred_spike = evaluate(hw, net, inp, outp, x)\n",
    "\n",
    "    # If we are using SpiNNaker2 chip, we have to delete the connection after use\n",
    "    if not use_brian2:\n",
    "        del hw\n",
    "    all_spikes[:,i:i+1,...] = pred_spike\n",
    "\n",
    "sim_name = \"s2_brian2\" if use_brian2 else \"s2\"\n",
    "np.save(f\"{sim_name}_corrected_activity.npy\", all_spikes[1:,...])\n",
    "np.save(f\"{sim_name}_uncorrected_activity.npy\", all_spikes[:-1,...])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Activity of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "fig, axs = plt.subplots(4,10)\n",
    "norse_spikes = np.load(\"Norse_activity.npy\")\n",
    "\n",
    "s2 = np.mean(all_spikes[1:,...], axis=0)\n",
    "s2 = np.mean(s2, axis=1)\n",
    "n = np.mean(norse_spikes, axis=0)\n",
    "n = np.mean(n, axis=1)\n",
    "d = np.mean(np.abs(norse_spikes-all_spikes[1:,...]), axis=0)\n",
    "d = np.mean(d, axis=1)\n",
    "d2 = np.abs(s2-n)\n",
    "\n",
    "\n",
    "axs[0,4].set_title(\"Activation of first layer from SpiNNaker2/Brian\")\n",
    "axs[1,4].set_title(\"Activation of first layer from Norse\")\n",
    "axs[2,4].set_title(\"Mean difference of S2 and Norse activity\")\n",
    "axs[3,4].set_title(\"Difference of mean S2 and Norse activity\")\n",
    "for idx in range(10):\n",
    "    axs[0, idx].imshow(s2[idx,...], vmin=0, vmax=0.017)\n",
    "    axs[1, idx].imshow(n[idx,...], vmin=0, vmax=0.017)\n",
    "    axs[2, idx].imshow(d[idx,...], vmin=0, vmax=0.017)\n",
    "    axs[3, idx].imshow(d2[idx,...], vmin=0, vmax=0.017)\n",
    "plt.tight_layout(pad=-3, h_pad=-2,w_pad=-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
